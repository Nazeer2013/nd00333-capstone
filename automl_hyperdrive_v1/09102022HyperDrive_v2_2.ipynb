{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Connect to your workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1662999762706
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing interactive authentication. Please follow the instructions on the terminal.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The default web browser has been opened at https://login.microsoftonline.com/organizations/oauth2/v2.0/authorize. Please continue the login in the web browser. If no web browser is available or if the web browser fails to open, use device code flow with `az login --use-device-code`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Interactive authentication successfully completed.\n",
            "Ready to use Azure ML 1.44.0 to work with nahmed30-azureml-workspace\n"
          ]
        }
      ],
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create Compute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1663000365476
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing cluster, use it.\n",
            "Succeeded.........................................................................................................\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Wait timeout has been reached\n",
            "Current provisioning state of AmlCompute is \"Succeeded\" and current node count is \"0\"\n"
          ]
        }
      ],
      "source": [
        "# Create compute\n",
        "\n",
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# NOTE: update the cluster name to match the existing cluster\n",
        "# Choose a name for your CPU cluster\n",
        "amlcompute_cluster_name = \"cpu-cluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',# for GPU, use \"STANDARD_NC6\"\n",
        "                                                           #vm_priority = 'lowpriority', # optional\n",
        "                                                           max_nodes=4)\n",
        "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
        "\n",
        "compute_target.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)\n",
        "# For a more detailed view of current AmlCompute status, use get_status().\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1663000369390
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Column3</th>\n",
              "      <th>Column4</th>\n",
              "      <th>Column5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5572</td>\n",
              "      <td>5572</td>\n",
              "      <td>50</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2</td>\n",
              "      <td>5169</td>\n",
              "      <td>43</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>ham</td>\n",
              "      <td>Sorry, I'll call later</td>\n",
              "      <td>bt not his girlfrnd... G o o d n i g h t . . .@\"</td>\n",
              "      <td>MK17 92H. 450Ppw 16\"</td>\n",
              "      <td>GNT:-)\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>4825</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          v1                      v2  \\\n",
              "count   5572                    5572   \n",
              "unique     2                    5169   \n",
              "top      ham  Sorry, I'll call later   \n",
              "freq    4825                      30   \n",
              "\n",
              "                                                  Column3  \\\n",
              "count                                                  50   \n",
              "unique                                                 43   \n",
              "top      bt not his girlfrnd... G o o d n i g h t . . .@\"   \n",
              "freq                                                    3   \n",
              "\n",
              "                      Column4  Column5  \n",
              "count                      12        6  \n",
              "unique                     10        5  \n",
              "top      MK17 92H. 450Ppw 16\"  GNT:-)\"  \n",
              "freq                        2        2  "
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "found = False\n",
        "key = \"UdacityPrjEmailSpamDataSet\"\n",
        "description_text = \"Spam Detection DataSet for Udacity Capstone Proj \"\n",
        "\n",
        "emailspam_ds = None\n",
        "if key in ws.datasets.keys(): \n",
        "        found = True\n",
        "        emailspam_ds = ws.datasets[key] \n",
        "if found:\n",
        "        emailspam_ds\n",
        "        df = emailspam_ds.to_pandas_dataframe()\n",
        "\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare a training script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1663000369583
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder ready.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "experiment_folder = '09122022_emailspam_training_hyperdrive_v1'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "print('Folder ready.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create  Python script to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting 09122022_emailspam_training_hyperdrive_v1/emailspam_training_09122022_v1.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $experiment_folder/emailspam_training_09122022_v1.py\n",
        "\n",
        "# Import libraries\n",
        "import argparse, joblib, os\n",
        "from azureml.core import Run\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import csv\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import tensorflow as tf\n",
        "import regex as re\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import pickle\n",
        "import tempfile\n",
        "from tensorflow.keras.models import Sequential, load_model, save_model, Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# from tensorflow.keras import models, layers\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# Get script arguments\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "# Input dataset\n",
        "parser.add_argument(\"--input-data\", type=str, dest='input_data', help='training dataset')\n",
        "\n",
        "#hyperdrive_feature\n",
        "parser.add_argument(\"--hyperdrive_feature\", type=bool, dest='hyperdrive_feature', help='hyperdrive feature')\n",
        "\n",
        "# Hyperparameters\n",
        "parser.add_argument('--units', type=int, default=64, help=\"Number of nodes\")\n",
        "parser.add_argument('--optimizer', type=str, default='adam', help=\"Algorithm of Choice\")\n",
        "\n",
        "# Add arguments to args collection\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Log Hyperparameter values \n",
        "run.log(\"Number of Nodes:\", np.int(args.units))  \n",
        "run.log(\"Algorithm of Choice:\", np.str(args.optimizer))  \n",
        "\n",
        "# load the email spam dataset -- Get the training data from the input\n",
        "print(\"Loading Email Spam Data...\")\n",
        "df = run.input_datasets['training_data'].to_pandas_dataframe() \n",
        "\n",
        "# Cleanup and Prepare Data # Find and eliminate stop words \n",
        "nltk.download('stopwords')\n",
        "stop_words= set(stopwords.words(\"english\"))\n",
        "stop_words.update(['https', 'http', 'amp', 'CO', 't', 'u', 'new', \"I'm\", \"would\"])\n",
        "\n",
        "\n",
        "spam = df.query(\"v1=='spam'\").v2.str.cat(sep=\" \")\n",
        "ham = df.query(\"v1=='ham'\").v2.str.cat(sep=\" \")\n",
        "\n",
        "# convert spam to 1 and ham to 0\n",
        "df = df.replace('spam', 1)\n",
        "df = df.replace('ham', 0)\n",
        "\n",
        "# Clean the text\n",
        "def clean_text(text):\n",
        "    whitespace = re.compile(r\"\\s+\")\n",
        "    web_address = re.compile(r\"(?i)http(s):\\/\\/[a-z0-9.~_\\-\\/]+\")\n",
        "    user = re.compile(r\"(?i)@[a-z0-9_]+\")\n",
        "    text = text.replace('.', '')\n",
        "    text = whitespace.sub(' ', text)\n",
        "    text = web_address.sub('', text)\n",
        "    text = user.sub('', text)\n",
        "    text = re.sub(r\"\\[[^()]*\\]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = re.sub(r'[^\\w\\s]','',text)\n",
        "    text = re.sub(r\"(?:@\\S*|#\\S*|http(?=.*://)\\S*)\", \"\", text)\n",
        "    return text.lower()\n",
        "\n",
        "df.v2 = [clean_text(item) for item in df.v2]\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.oov_token = '<oovToken>'\n",
        "tokenizer.fit_on_texts(df.v2)\n",
        "vocab = tokenizer.word_index\n",
        "vocabCount = len(vocab)+1\n",
        "\n",
        "\n",
        "# Split Train and Test\n",
        "SPLIT = 5000\n",
        "\n",
        "# Split data into training set and test set\n",
        "xTrain = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(df.v2.to_numpy()), padding='pre', maxlen=171)\n",
        "yTrain = df.v1.to_numpy()\n",
        "\n",
        "dim = xTrain.shape[1]\n",
        "xTest = xTrain[SPLIT:]\n",
        "yTest = yTrain[SPLIT:]\n",
        "\n",
        "xTrain = xTrain[:SPLIT]\n",
        "yTrain = yTrain[:SPLIT]\n",
        "\n",
        "# Train a Keras Sequential classification model without the specified hyperparameters\n",
        "print('Training a classification model')\n",
        "\n",
        "#------------------------------------------------------------\n",
        "#model = tf.keras.Sequential()\n",
        "#model.add(tf.keras.layers.Embedding(input_dim=vocabCount+1, output_dim=64, input_length=dim))\n",
        "#model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "#model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#model.summary()\n",
        "\n",
        "#--------------------------------------------------------------\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(input_dim=vocabCount+1, output_dim=64, input_length=dim))\n",
        "model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "# for i in range(args.num_layers):\n",
        "model.add(tf.keras.layers.Dense(args.units, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=args.optimizer, metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "hist = model.fit(xTrain, yTrain, batch_size=32, epochs=100, initial_epoch=6, validation_data=(xTest, yTest))\n",
        "\n",
        "# calculate accuracy\n",
        "# y_hat = model.predict(xTest)\n",
        "# acc = np.average(y_hat == yTest)\n",
        "# print('Accuracy:', acc)\n",
        "# run.log('Accuracy', np.float64(acc))\n",
        "\n",
        "print('hist type: ', type(hist))\n",
        "\n",
        "eval_result = model.evaluate(xTest, yTest)\n",
        "\n",
        "print('evaluated results: ', eval_result)\n",
        "\n",
        "# run.log('loss', np.float64(eval_result[0]))\n",
        "run.log('Accuracy', np.float64(eval_result[1]))\n",
        "\n",
        "\n",
        "# calculate AUC\n",
        "# y_scores = model.predict_proba(xTest)\n",
        "# auc = roc_auc_score(yTest,y_scores[:,1])\n",
        "# print('AUC: ' + str(auc))\n",
        "# run.log('AUC', np.float(auc))\n",
        "\n",
        "#for x in ['acc','val_acc']:\n",
        "    #run.log('Accuracy', hist.history[x[0]])\n",
        "#    print (hist.history[x])\n",
        "#    print (hist.history[x[0]])\n",
        "#    plt.plot(hist.history[x])\n",
        "\n",
        "# Save the model in the run outputs\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "joblib.dump(value=model, filename='outputs/emailspam_model09122022.pkl')\n",
        "    \n",
        "\n",
        "run.complete()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You'll need a Python environment to be hosted on the compute, so let's define that as Conda configuration file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting 09122022_emailspam_training_hyperdrive_v1/emailspam_hyperdrive_env_09122022_v1.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile $experiment_folder/emailspam_hyperdrive_env_09122022_v1.yml\n",
        "name: batch_environment\n",
        "dependencies:\n",
        "- python=3.8.5\n",
        "- scikit-learn\n",
        "- pandas\n",
        "- numpy\n",
        "- regex\n",
        "- tensorflow\n",
        "- nltk\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run a hyperparameter tuning experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "gather": {
          "logged": 1663000986438
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'runId': 'HD_3800e839-11e3-4707-ade7-885f37c61a72',\n",
              " 'target': 'cpu-cluster',\n",
              " 'status': 'Completed',\n",
              " 'startTimeUtc': '2022-09-13T16:53:22.966174Z',\n",
              " 'endTimeUtc': '2022-09-13T16:58:25.810902Z',\n",
              " 'services': {},\n",
              " 'properties': {'primary_metric_config': '{\"name\":\"Accuracy\",\"goal\":\"maximize\"}',\n",
              "  'resume_from': 'null',\n",
              "  'runTemplate': 'HyperDrive',\n",
              "  'azureml.runsource': 'hyperdrive',\n",
              "  'platform': 'AML',\n",
              "  'ContentSnapshotId': '5cca0151-76d8-4b0e-9b38-14c0e67eb941',\n",
              "  'user_agent': 'python/3.8.12 (macOS-10.15.7-x86_64-i386-64bit) msrest/0.6.21 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.44.0',\n",
              "  'space_size': '4',\n",
              "  'score': '0.9877622127532959',\n",
              "  'best_child_run_id': 'HD_3800e839-11e3-4707-ade7-885f37c61a72_3',\n",
              "  'best_metric_status': 'Succeeded',\n",
              "  'best_data_container_id': 'dcid.HD_3800e839-11e3-4707-ade7-885f37c61a72_3'},\n",
              " 'inputDatasets': [],\n",
              " 'outputDatasets': [],\n",
              " 'runDefinition': {'configuration': None,\n",
              "  'attribution': None,\n",
              "  'telemetryValues': {'amlClientType': 'azureml-sdk-train',\n",
              "   'amlClientModule': '[Scrubbed]',\n",
              "   'amlClientFunction': '[Scrubbed]',\n",
              "   'tenantId': 'db05faca-c82a-4b9d-b9c5-0f64b6755421',\n",
              "   'amlClientRequestId': 'd170446a-bb50-46c1-97d1-77c5cfc90e6d',\n",
              "   'amlClientSessionId': 'e8e329db-a822-4b22-9b92-e9f37746daed',\n",
              "   'subscriptionId': '16bc73b5-82be-47f2-b5ab-f2373344794c',\n",
              "   'estimator': 'NoneType',\n",
              "   'samplingMethod': 'RANDOM',\n",
              "   'terminationPolicy': 'Default',\n",
              "   'primaryMetricGoal': 'maximize',\n",
              "   'maxTotalRuns': 24,\n",
              "   'maxConcurrentRuns': 2,\n",
              "   'maxDurationMinutes': 10080,\n",
              "   'vmSize': None},\n",
              "  'snapshotId': '5cca0151-76d8-4b0e-9b38-14c0e67eb941',\n",
              "  'snapshots': [],\n",
              "  'sourceCodeDataReference': None,\n",
              "  'parentRunId': None,\n",
              "  'dataContainerId': None,\n",
              "  'runType': None,\n",
              "  'displayName': None,\n",
              "  'environmentAssetId': None,\n",
              "  'properties': {},\n",
              "  'tags': {},\n",
              "  'aggregatedArtifactPath': None},\n",
              " 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://nahmed30storage.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_3800e839-11e3-4707-ade7-885f37c61a72/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=RQ31Zts1sxiT45mtpXx9HPPyvafZQTc8QaPXu3GgCuM%3D&skoid=990e57a2-6b09-4324-b33f-71ef714de994&sktid=db05faca-c82a-4b9d-b9c5-0f64b6755421&skt=2022-09-13T13%3A35%3A58Z&ske=2022-09-14T21%3A45%3A58Z&sks=b&skv=2019-07-07&st=2022-09-13T16%3A49%3A07Z&se=2022-09-14T00%3A59%3A07Z&sp=r'},\n",
              " 'submittedBy': 'Nazeer Ahmed'}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.train.hyperdrive import RandomParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Create a Python environment for the experiment\n",
        "hyper_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/emailspam_hyperdrive_env_09122022_v1.yml\")\n",
        "\n",
        "# Get the training dataset\n",
        "# emailspam_ds = ws.datasets.get(\"UdacityPrjEmailSpamDataSet\")\n",
        "\n",
        "hyperdrive_feature = True\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='emailspam_training_09122022_v1.py',\n",
        "                                # Add non-hyperparameter arguments -in this case, the training dataset\n",
        "                                arguments = ['--input-data', emailspam_ds.as_named_input('training_data'),\n",
        "                                '--hyperdrive_feature', hyperdrive_feature],\n",
        "                                environment=hyper_env,\n",
        "                                compute_target = amlcompute_cluster_name)\n",
        "\n",
        "                                \n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "params = RandomParameterSampling( \n",
        "    {\n",
        "    \"--units\": choice(64, 80),\n",
        "    \"--optimizer\": choice('adam', 'sgd')\n",
        "    })\n",
        "\n",
        "# Configure hyperdrive settings\n",
        "hyperdrive = HyperDriveConfig(run_config=script_config, \n",
        "                          hyperparameter_sampling=params, \n",
        "                          policy=None, # No early stopping policy\n",
        "                          primary_metric_name='Accuracy', # Find the highest Accuracy metric\n",
        "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
        "                          max_total_runs=24, # Restict the experiment to 48 iterations\n",
        "                          max_concurrent_runs=2) # Run up to 2 iterations in parallel\n",
        "\n",
        "# Run the experiment\n",
        "experiment = Experiment(workspace=ws, name='emailspam-hyperdrive-exp-09122022-v1')\n",
        "run = experiment.submit(config=hyperdrive)\n",
        "\n",
        "# Show the status in the notebook as the experiment runs\n",
        "# RunDetails(run).show()\n",
        "run.wait_for_completion()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Determine the best performing run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "gather": {
          "logged": 1663000986637
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'run_id': 'HD_3800e839-11e3-4707-ade7-885f37c61a72_3', 'hyperparameters': '{\"--optimizer\": \"adam\", \"--units\": 64}', 'best_primary_metric': 0.9877622127532959, 'status': 'Completed'}\n",
            "{'run_id': 'HD_3800e839-11e3-4707-ade7-885f37c61a72_2', 'hyperparameters': '{\"--optimizer\": \"adam\", \"--units\": 80}', 'best_primary_metric': 0.9860140085220337, 'status': 'Completed'}\n",
            "{'run_id': 'HD_3800e839-11e3-4707-ade7-885f37c61a72_1', 'hyperparameters': '{\"--optimizer\": \"sgd\", \"--units\": 80}', 'best_primary_metric': 0.8706293702125549, 'status': 'Completed'}\n",
            "{'run_id': 'HD_3800e839-11e3-4707-ade7-885f37c61a72_0', 'hyperparameters': '{\"--optimizer\": \"sgd\", \"--units\": 64}', 'best_primary_metric': 0.868881106376648, 'status': 'Completed'}\n"
          ]
        }
      ],
      "source": [
        "# Print all child runs, sorted by the primary metric\n",
        "for child_run in run.get_children_sorted_by_primary_metric():\n",
        "    print(child_run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "gather": {
          "logged": 1663000987342
        }
      },
      "outputs": [],
      "source": [
        "# Get the best run, and its metrics and arguments\n",
        "best_run = run.get_best_run_by_primary_metric()\n",
        "best_run_metrics = best_run.get_metrics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "gather": {
          "logged": 1663006851428
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Run Id:  HD_3800e839-11e3-4707-ade7-885f37c61a72_3\n"
          ]
        }
      ],
      "source": [
        "script_arguments = best_run.get_details() ['runDefinition']['arguments']\n",
        "print('Best Run Id: ', best_run.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "gather": {
          "logged": 1663002226439
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " -Accuracy: 0.9877622127532959\n",
            " -Arguments: ['--input-data', 'DatasetConsumptionConfig:training_data', '--hyperdrive_feature', 'True', '--optimizer', 'adam', '--units', '64']\n"
          ]
        }
      ],
      "source": [
        "print(' -Accuracy:', best_run_metrics['Accuracy'])\n",
        "print(' -Arguments:',script_arguments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that you've found the best run, you can register the model it trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "gather": {
          "logged": 1663002506771
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "# Register model\n",
        "# outputs/emailspam_model09122022.pkl\n",
        "reg_model = best_run.register_model(model_path='outputs/emailspam_model09122022.pkl', model_name='emailspam_model_09102022',\n",
        "                        tags={'Training context':'Hyperdrive'},\n",
        "                        properties={'Accuracy': best_run_metrics['Accuracy']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "gather": {
          "logged": 1663008985510
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "# Combine scoring script & environment in Inference configuration\n",
        "inference_config = InferenceConfig(entry_script=\"09102022/score.py\",\n",
        "                                   environment=hyper_env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "gather": {
          "logged": 1663009129493
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.webservice.aci import AciWebservice\n",
        "# Set deployment configuration\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
        "                                                       memory_gb = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "gather": {
          "logged": 1663009290514
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Define the model, inference, & deployment configuration and web service name and location to deploy\n",
        "service = Model.deploy(workspace = ws,\n",
        "                       name = \"my-emailspam-service4\",\n",
        "                       models = [reg_model],\n",
        "                       inference_config = inference_config,\n",
        "                       deployment_config = deployment_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "gather": {
          "logged": 1663009486696
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AciWebservice(workspace=Workspace.create(name='nahmed30-azureml-workspace', subscription_id='16bc73b5-82be-47f2-b5ab-f2373344794c', resource_group='epe-poc-nazeer'), name=my-emailspam-service4, image_id=None, image_digest=None, compute_type=ACI, state=Transitioning, scoring_uri=None, tags={}, properties={'azureml.git.repository_uri': 'https://github.com/Nazeer2013/nd00333-capstone.git', 'mlflow.source.git.repoURL': 'https://github.com/Nazeer2013/nd00333-capstone.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': 'd9d915e92aee08ac2f8a520e60895638f6e15921', 'mlflow.source.git.commit': 'd9d915e92aee08ac2f8a520e60895638f6e15921', 'azureml.git.dirty': 'True'}, created_by={'userObjectId': 'a8930881-263c-498d-8975-58e6a0c28f2c', 'userPuId': '10032001567EC76C', 'userIdp': None, 'userAltSecId': None, 'userIss': 'https://sts.windows.net/db05faca-c82a-4b9d-b9c5-0f64b6755421/', 'userTenantId': 'db05faca-c82a-4b9d-b9c5-0f64b6755421', 'userName': 'Nazeer Ahmed', 'upn': 'nahmed30@optumcloud.com'})"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "service"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
