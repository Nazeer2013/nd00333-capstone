{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Connect to your workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1662999762706
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ready to use Azure ML 1.44.0 to work with nahmed30-azureml-workspace\n"
          ]
        }
      ],
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create Compute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1663000365476
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing cluster, use it.\n",
            "Succeeded.......................................................................................................\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Wait timeout has been reached\n",
            "Current provisioning state of AmlCompute is \"Succeeded\" and current node count is \"0\"\n"
          ]
        }
      ],
      "source": [
        "# Create compute\n",
        "\n",
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# NOTE: update the cluster name to match the existing cluster\n",
        "# Choose a name for your CPU cluster\n",
        "amlcompute_cluster_name = \"cpu-cluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',# for GPU, use \"STANDARD_NC6\"\n",
        "                                                           #vm_priority = 'lowpriority', # optional\n",
        "                                                           max_nodes=4)\n",
        "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
        "\n",
        "compute_target.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)\n",
        "# For a more detailed view of current AmlCompute status, use get_status().\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1663000369390
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Column3</th>\n",
              "      <th>Column4</th>\n",
              "      <th>Column5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5572</td>\n",
              "      <td>5572</td>\n",
              "      <td>50</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2</td>\n",
              "      <td>5169</td>\n",
              "      <td>43</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>ham</td>\n",
              "      <td>Sorry, I'll call later</td>\n",
              "      <td>bt not his girlfrnd... G o o d n i g h t . . .@\"</td>\n",
              "      <td>GE</td>\n",
              "      <td>GNT:-)\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>4825</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          v1                      v2  \\\n",
              "count   5572                    5572   \n",
              "unique     2                    5169   \n",
              "top      ham  Sorry, I'll call later   \n",
              "freq    4825                      30   \n",
              "\n",
              "                                                  Column3 Column4  Column5  \n",
              "count                                                  50      12        6  \n",
              "unique                                                 43      10        5  \n",
              "top      bt not his girlfrnd... G o o d n i g h t . . .@\"      GE  GNT:-)\"  \n",
              "freq                                                    3       2        2  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "found = False\n",
        "key = \"UdacityPrjEmailSpamDataSet\"\n",
        "description_text = \"Spam Detection DataSet for Udacity Capstone Proj \"\n",
        "\n",
        "emailspam_ds = None\n",
        "if key in ws.datasets.keys(): \n",
        "        found = True\n",
        "        emailspam_ds = ws.datasets[key] \n",
        "if found:\n",
        "        emailspam_ds\n",
        "        df = emailspam_ds.to_pandas_dataframe()\n",
        "\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare a training script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1663000369583
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder ready.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "experiment_folder = 'smsspam_hyperdrive_experiment_v1'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "print('Folder ready.')\n",
        "\n",
        "train_script_name='smsspam_training_v09132022_1.py'\n",
        "train_env_yml='smsspam_hyperdrive_env_v09132022_1.yml'\n",
        "experiment_name='smsspam-hyperdrive-exp-v09122022-1'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create  Python script to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting smsspam_hyperdrive_experiment_v1/smsspam_training_v09132022_1.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $experiment_folder/smsspam_training_v09132022_1.py\n",
        "\n",
        "# Import libraries\n",
        "import argparse, joblib, os\n",
        "from azureml.core import Run\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import csv\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import tensorflow as tf\n",
        "import regex as re\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import pickle\n",
        "import tempfile\n",
        "from tensorflow.keras.models import Sequential, load_model, save_model, Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# from tensorflow.keras import models, layers\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# Get script arguments\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "# Input dataset\n",
        "parser.add_argument(\"--input-data\", type=str, dest='input_data', help='training dataset')\n",
        "\n",
        "#hyperdrive_feature\n",
        "parser.add_argument(\"--hyperdrive_feature\", type=bool, dest='hyperdrive_feature', help='hyperdrive feature')\n",
        "\n",
        "# Hyperparameters\n",
        "parser.add_argument('--units', type=int, default=64, help=\"Number of nodes\")\n",
        "parser.add_argument('--optimizer', type=str, default='adam', help=\"Algorithm of Choice\")\n",
        "\n",
        "# Add arguments to args collection\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Log Hyperparameter values \n",
        "run.log(\"Number of Nodes:\", np.int(args.units))  \n",
        "run.log(\"Algorithm of Choice:\", np.str(args.optimizer))  \n",
        "\n",
        "# load the email spam dataset -- Get the training data from the input\n",
        "print(\"Loading Email Spam Data...\")\n",
        "df = run.input_datasets['training_data'].to_pandas_dataframe() \n",
        "\n",
        "# Cleanup and Prepare Data # Find and eliminate stop words \n",
        "nltk.download('stopwords')\n",
        "stop_words= set(stopwords.words(\"english\"))\n",
        "stop_words.update(['https', 'http', 'amp', 'CO', 't', 'u', 'new', \"I'm\", \"would\"])\n",
        "\n",
        "\n",
        "spam = df.query(\"v1=='spam'\").v2.str.cat(sep=\" \")\n",
        "ham = df.query(\"v1=='ham'\").v2.str.cat(sep=\" \")\n",
        "\n",
        "# convert spam to 1 and ham to 0\n",
        "df = df.replace('spam', 1)\n",
        "df = df.replace('ham', 0)\n",
        "\n",
        "# Clean the text\n",
        "def clean_text(text):\n",
        "    whitespace = re.compile(r\"\\s+\")\n",
        "    web_address = re.compile(r\"(?i)http(s):\\/\\/[a-z0-9.~_\\-\\/]+\")\n",
        "    user = re.compile(r\"(?i)@[a-z0-9_]+\")\n",
        "    text = text.replace('.', '')\n",
        "    text = whitespace.sub(' ', text)\n",
        "    text = web_address.sub('', text)\n",
        "    text = user.sub('', text)\n",
        "    text = re.sub(r\"\\[[^()]*\\]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = re.sub(r'[^\\w\\s]','',text)\n",
        "    text = re.sub(r\"(?:@\\S*|#\\S*|http(?=.*://)\\S*)\", \"\", text)\n",
        "    return text.lower()\n",
        "\n",
        "df.v2 = [clean_text(item) for item in df.v2]\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.oov_token = '<oovToken>'\n",
        "tokenizer.fit_on_texts(df.v2)\n",
        "vocab = tokenizer.word_index\n",
        "vocabCount = len(vocab)+1\n",
        "\n",
        "\n",
        "# Split Train and Test\n",
        "SPLIT = 5000\n",
        "\n",
        "# Split data into training set and test set\n",
        "xTrain = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(df.v2.to_numpy()), padding='pre', maxlen=171)\n",
        "yTrain = df.v1.to_numpy()\n",
        "\n",
        "dim = xTrain.shape[1]\n",
        "xTest = xTrain[SPLIT:]\n",
        "yTest = yTrain[SPLIT:]\n",
        "\n",
        "xTrain = xTrain[:SPLIT]\n",
        "yTrain = yTrain[:SPLIT]\n",
        "\n",
        "# Train a Keras Sequential classification model without the specified hyperparameters\n",
        "print('Training a classification model')\n",
        "\n",
        "#------------------------------------------------------------\n",
        "#model = tf.keras.Sequential()\n",
        "#model.add(tf.keras.layers.Embedding(input_dim=vocabCount+1, output_dim=64, input_length=dim))\n",
        "#model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "#model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#model.summary()\n",
        "\n",
        "#--------------------------------------------------------------\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(input_dim=vocabCount+1, output_dim=64, input_length=dim))\n",
        "model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "# for i in range(args.num_layers):\n",
        "model.add(tf.keras.layers.Dense(args.units, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=args.optimizer, metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "history = model.fit(xTrain, yTrain, batch_size=32, epochs=30, initial_epoch=6, validation_data=(xTest, yTest))\n",
        "\n",
        "# calculate accuracy\n",
        "# y_hat = model.predict(xTest)\n",
        "# acc = np.average(y_hat == yTest)\n",
        "# print('Accuracy:', acc)\n",
        "# run.log('Accuracy', np.float64(acc))\n",
        "\n",
        "print('history type: ', type(history))\n",
        "\n",
        "eval_result = model.evaluate(xTest, yTest)\n",
        "\n",
        "print('evaluated results: ', eval_result)\n",
        "\n",
        "run.log('Loss', np.float64(eval_result[0]))\n",
        "run.log('Accuracy', np.float64(eval_result[1]))\n",
        "\n",
        "accuracy_pct = np.float64(eval_result[1])\n",
        "\n",
        "print('Model Accuracy:  %.2f' % (accuracy_pct * 100))\n",
        "\n",
        "# calculate AUC\n",
        "# y_scores = model.predict_proba(xTest)\n",
        "# auc = roc_auc_score(yTest,y_scores[:,1])\n",
        "# print('AUC: ' + str(auc))\n",
        "# run.log('AUC', np.float(auc))\n",
        "\n",
        "#for x in ['acc','val_acc']:\n",
        "    #run.log('Accuracy', hist.history[x[0]])\n",
        "#    print (hist.history[x])\n",
        "#    print (hist.history[x[0]])\n",
        "#    plt.plot(hist.history[x])\n",
        "\n",
        "# Create the outputs folder - save any outputs you want managed by AzureML here\n",
        "os.makedirs('./outputs', exist_ok=True)\n",
        "\n",
        "print('Saving model history...')\n",
        "with open(f'outputs/model.history', 'wb') as f:\n",
        "        pickle.dump(history.history, f)\n",
        "\n",
        "print('Saving model...')\n",
        "model.save(f'outputs/')\n",
        "\n",
        "model.save(f'outputs/sms_spam_check_model_v1.h5')\n",
        "\n",
        "print('Model is saved Done!')\n",
        "print('-'*100)\n",
        "\n",
        "\n",
        "# Save the model in the run outputs\n",
        "#os.makedirs('outputs', exist_ok=True)\n",
        "#joblib.dump(value=model, filename='outputs/emailspam_model09122022.pkl')\n",
        "    \n",
        "\n",
        "run.complete()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You'll need a Python environment to be hosted on the compute, so let's define that as Conda configuration file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting smsspam_hyperdrive_experiment_v1/smsspam_hyperdrive_env_v09132022_1.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile $experiment_folder/smsspam_hyperdrive_env_v09132022_1.yml\n",
        "name: batch_environment\n",
        "dependencies:\n",
        "- python=3.8.5\n",
        "- scikit-learn\n",
        "- pandas\n",
        "- numpy\n",
        "- regex\n",
        "- tensorflow\n",
        "- nltk\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run a hyperparameter tuning experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "gather": {
          "logged": 1663000986438
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'runId': 'HD_cba4c1da-9839-4248-918e-810e73b7e452',\n",
              " 'target': 'cpu-cluster',\n",
              " 'status': 'Completed',\n",
              " 'startTimeUtc': '2022-09-14T03:47:48.904986Z',\n",
              " 'endTimeUtc': '2022-09-14T03:49:52.069834Z',\n",
              " 'services': {},\n",
              " 'properties': {'primary_metric_config': '{\"name\":\"Accuracy\",\"goal\":\"maximize\"}',\n",
              "  'resume_from': 'null',\n",
              "  'runTemplate': 'HyperDrive',\n",
              "  'azureml.runsource': 'hyperdrive',\n",
              "  'platform': 'AML',\n",
              "  'ContentSnapshotId': '9b877abe-e877-4e6a-adf6-aa613dfdbc73',\n",
              "  'user_agent': 'python/3.8.12 (macOS-10.15.7-x86_64-i386-64bit) msrest/0.6.21 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.44.0',\n",
              "  'space_size': '1',\n",
              "  'score': '0.9860140085220337',\n",
              "  'best_child_run_id': 'HD_cba4c1da-9839-4248-918e-810e73b7e452_0',\n",
              "  'best_metric_status': 'Succeeded',\n",
              "  'best_data_container_id': 'dcid.HD_cba4c1da-9839-4248-918e-810e73b7e452_0'},\n",
              " 'inputDatasets': [],\n",
              " 'outputDatasets': [],\n",
              " 'runDefinition': {'configuration': None,\n",
              "  'attribution': None,\n",
              "  'telemetryValues': {'amlClientType': 'azureml-sdk-train',\n",
              "   'amlClientModule': '[Scrubbed]',\n",
              "   'amlClientFunction': '[Scrubbed]',\n",
              "   'tenantId': 'db05faca-c82a-4b9d-b9c5-0f64b6755421',\n",
              "   'amlClientRequestId': 'd4260f8c-5be2-4f22-9ebb-dac179428609',\n",
              "   'amlClientSessionId': 'bc2dd022-79f5-4c23-a531-2ddf0cf9db54',\n",
              "   'subscriptionId': '16bc73b5-82be-47f2-b5ab-f2373344794c',\n",
              "   'estimator': 'NoneType',\n",
              "   'samplingMethod': 'RANDOM',\n",
              "   'terminationPolicy': 'Default',\n",
              "   'primaryMetricGoal': 'maximize',\n",
              "   'maxTotalRuns': 24,\n",
              "   'maxConcurrentRuns': 2,\n",
              "   'maxDurationMinutes': 10080,\n",
              "   'vmSize': None},\n",
              "  'snapshotId': '9b877abe-e877-4e6a-adf6-aa613dfdbc73',\n",
              "  'snapshots': [],\n",
              "  'sourceCodeDataReference': None,\n",
              "  'parentRunId': None,\n",
              "  'dataContainerId': None,\n",
              "  'runType': None,\n",
              "  'displayName': None,\n",
              "  'environmentAssetId': None,\n",
              "  'properties': {},\n",
              "  'tags': {},\n",
              "  'aggregatedArtifactPath': None},\n",
              " 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://nahmed30storage.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_cba4c1da-9839-4248-918e-810e73b7e452/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=RwjrU%2FkUQa2VGVlItZJv9Ra80i0%2FFx7JpU%2BtWWrAi1Q%3D&skoid=990e57a2-6b09-4324-b33f-71ef714de994&sktid=db05faca-c82a-4b9d-b9c5-0f64b6755421&skt=2022-09-14T00%3A50%3A23Z&ske=2022-09-15T09%3A00%3A23Z&sks=b&skv=2019-07-07&st=2022-09-14T03%3A40%3A22Z&se=2022-09-14T11%3A50%3A22Z&sp=r'},\n",
              " 'submittedBy': 'Nazeer Ahmed'}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.train.hyperdrive import RandomParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Create a Python environment for the experiment\n",
        "hyper_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/\" +train_env_yml)\n",
        "\n",
        "\n",
        "hyperdrive_feature = True\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script=train_script_name,\n",
        "                                # Add non-hyperparameter arguments -in this case, the training dataset\n",
        "                                arguments = ['--input-data', emailspam_ds.as_named_input('training_data'),\n",
        "                                '--hyperdrive_feature', hyperdrive_feature],\n",
        "                                environment=hyper_env,\n",
        "                                compute_target = amlcompute_cluster_name)\n",
        "\n",
        "                                \n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "params = RandomParameterSampling( \n",
        "    {\n",
        "    \"--units\": choice(80),\n",
        "    \"--optimizer\": choice('adam')\n",
        "    })\n",
        "\n",
        "# Configure hyperdrive settings\n",
        "hyperdrive = HyperDriveConfig(run_config=script_config, \n",
        "                          hyperparameter_sampling=params, \n",
        "                          policy=None, # No early stopping policy\n",
        "                          primary_metric_name='Accuracy', # Find the highest Accuracy metric\n",
        "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
        "                          max_total_runs=24, # Restict the experiment to 48 iterations\n",
        "                          max_concurrent_runs=2) # Run up to 2 iterations in parallel\n",
        "\n",
        "# Run the experiment\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=hyperdrive)\n",
        "\n",
        "# Show the status in the notebook as the experiment runs\n",
        "\n",
        "# RunDetails(run).show()\n",
        "run.wait_for_completion()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Determine the best performing run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "gather": {
          "logged": 1663000986637
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'run_id': 'HD_cba4c1da-9839-4248-918e-810e73b7e452_0', 'hyperparameters': '{\"--optimizer\": \"adam\", \"--units\": 80}', 'best_primary_metric': 0.9860140085220337, 'status': 'Completed'}\n"
          ]
        }
      ],
      "source": [
        "# Print all child runs, sorted by the primary metric\n",
        "for child_run in run.get_children_sorted_by_primary_metric():\n",
        "    print(child_run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1663000987342
        }
      },
      "outputs": [],
      "source": [
        "# Get the best run, and its metrics and arguments\n",
        "best_run = run.get_best_run_by_primary_metric()\n",
        "best_run_metrics = best_run.get_metrics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "gather": {
          "logged": 1663006851428
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Run Id:  HD_cba4c1da-9839-4248-918e-810e73b7e452_0\n"
          ]
        }
      ],
      "source": [
        "script_arguments = best_run.get_details() ['runDefinition']['arguments']\n",
        "print('Best Run Id: ', best_run.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "gather": {
          "logged": 1663002226439
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " -Accuracy: 0.9860140085220337\n",
            " -Arguments: ['--input-data', 'DatasetConsumptionConfig:training_data', '--hyperdrive_feature', 'True', '--optimizer', 'adam', '--units', '80']\n"
          ]
        }
      ],
      "source": [
        "print(' -Accuracy:', best_run_metrics['Accuracy'])\n",
        "print(' -Arguments:',script_arguments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that you've found the best run, you can register the model it trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the files.\n",
        "best_run.download_files(output_directory='smsspam_model_output_v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 171, 64)           550848    \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 64)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 80)                5200      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2592      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 558,673\n",
            "Trainable params: 558,673\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.keras as K\n",
        "\n",
        "# load the model\n",
        "model = K.models.load_model(f'smsspam_model_output_v2/outputs/sms_spam_check_model_v1.h5')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'sequential'"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd165acacd0>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# load model history\n",
        "with open(f'smsspam_model_output_v2/outputs/model.history', 'rb') as fp:\n",
        "    history = pickle.load(fp)\n",
        "    \n",
        "plt.plot(history['accuracy'], label='Accuracy')\n",
        "plt.plot(history['loss'], label='Loss')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "smsspam_model_output_v2/outputs\n"
          ]
        }
      ],
      "source": [
        "MODEL_DIR = \"smsspam_model_output_v2/outputs\" \n",
        "export_path = os.path.join(MODEL_DIR) \n",
        "print(export_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fd181712b80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('signature_function', 'signature_key'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fd181712b80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('signature_function', 'signature_key'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "INFO:tensorflow:Assets written to: smsspam_model_output_v2/outputs/assets\n",
            "\n",
            "export_path = smsspam_model_output_v2/outputs\n"
          ]
        }
      ],
      "source": [
        "model.save(export_path, save_format=\"tf\") \n",
        "print('\\nexport_path = {}'.format(export_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['embedding_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 171)\n",
            "        name: serving_default_embedding_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_2'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 171), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          embedding_input: TensorSpec(shape=(None, 171), dtype=tf.float32, name='embedding_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          embedding_input: TensorSpec(shape=(None, 171), dtype=tf.float32, name='embedding_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 171), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          embedding_input: TensorSpec(shape=(None, 171), dtype=tf.float32, name='embedding_input')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 171), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 171), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          embedding_input: TensorSpec(shape=(None, 171), dtype=tf.float32, name='embedding_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          embedding_input: TensorSpec(shape=(None, 171), dtype=tf.float32, name='embedding_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).call_and_return_all_conditional_losses\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root)._default_save_signature\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.__call__\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.call_and_return_all_conditional_losses\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.__call__\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.call_and_return_all_conditional_losses\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.__call__\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.call_and_return_all_conditional_losses\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.__call__\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.call_and_return_all_conditional_losses\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.__call__\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.call_and_return_all_conditional_losses\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__.trace_0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__.trace_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__.trace_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).__call__.trace_3\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).call_and_return_all_conditional_losses.trace_0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).call_and_return_all_conditional_losses.trace_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).call_and_return_all_conditional_losses.trace_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).call_and_return_all_conditional_losses.trace_3\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures.serving_default\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.__call__.trace_0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.call_and_return_all_conditional_losses.trace_0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.__call__.trace_0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-1.call_and_return_all_conditional_losses.trace_0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.__call__.trace_0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.call_and_return_all_conditional_losses.trace_0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.__call__.trace_0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.call_and_return_all_conditional_losses.trace_0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.__call__.trace_0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.call_and_return_all_conditional_losses.trace_0\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "gather": {
          "logged": 1663002506771
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "# Register model\n",
        "# outputs/emailspam_model09122022.pkl\n",
        "reg_model = best_run.register_model(model_path='outputs/sms_spam_check_model_v1.h5', model_name='sequential',\n",
        "                        tags={'Training context':'Hyperdrive'},\n",
        "                        properties={'Accuracy': best_run_metrics['Accuracy']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Model(workspace=Workspace.create(name='nahmed30-azureml-workspace', subscription_id='16bc73b5-82be-47f2-b5ab-f2373344794c', resource_group='epe-poc-nazeer'), name=sequential, id=sequential:2, version=2, tags={'Training context': 'Hyperdrive'}, properties={'Accuracy': '0.9860140085220337'})"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "keras.engine.sequential.Sequential"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "from inference_schema.schema_decorators import input_schema, output_schema\n",
        "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
        "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
        "from inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "input_sample = pd.DataFrame({\"v2\": pd.Series([\"Who are you\"], dtype=\"object\"), \"Column4\": pd.Series([\"example_value\"], dtype=\"object\"), \"Column5\": pd.Series([\"example_value\"], dtype=\"object\"), \"Column6\": pd.Series([\"example_value\"], dtype=\"object\")})\n",
        "output_sample = np.array([\"example_value\"])\n",
        "method_sample = StandardPythonParameterType(\"predict\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function inference_schema.schema_decorators.output_schema.<locals>.decorator_input(user_run, instance, args, kwargs)>"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_schema('method', method_sample, convert_to_provided_type=False)\n",
        "input_schema('data', PandasParameterType(input_sample))\n",
        "output_schema(NumpyParameterType(output_sample))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "data =  {\n",
        "  \"data\": [\n",
        "    {\n",
        "      \"v2\": \"example_value\",\n",
        "      \"Column4\": \"example_value\",\n",
        "      \"Column5\": \"example_value\",\n",
        "      \"Column6\": \"example_value\"\n",
        "    }\n",
        "  ],\n",
        "  \"method\": \"predict\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'example_value'"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.get('data')[0].get('v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    Who are you\n",
              "Name: v2, dtype: object"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_sample.get('v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Who are you'], dtype=object)"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_sample.get('v2').values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Who are you'"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_sample.get('v2')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = model.predict(input_sample.get('v2')[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7fd165fc8af0>"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"You won $100 click link below to collect\"\n",
        "processedText = clean_text(text)\n",
        "#print(processedText)\n",
        "finalText = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([processedText]), padding='pre', maxlen=171)\n",
        "print(finalText)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = model.predict(\"This is a test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "result = model.predict(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = model.predict(\"This is a test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    whitespace = re.compile(r\"\\s+\")\n",
        "    web_address = re.compile(r\"(?i)http(s):\\/\\/[a-z0-9.~_\\-\\/]+\")\n",
        "    user = re.compile(r\"(?i)@[a-z0-9_]+\")\n",
        "    text = text.replace('.', '')\n",
        "    text = whitespace.sub(' ', text)\n",
        "    text = web_address.sub('', text)\n",
        "    text = user.sub('', text)\n",
        "    text = re.sub(r\"\\[[^()]*\\]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = re.sub(r'[^\\w\\s]','',text)\n",
        "    text = re.sub(r\"(?:@\\S*|#\\S*|http(?=.*://)\\S*)\", \"\", text)\n",
        "    return text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.oov_token = '<oovToken>'\n",
        "tokenizer.fit_on_texts(\"You won $100 \")\n",
        "vocab = tokenizer.word_index\n",
        "vocabCount = len(vocab)+1\n",
        "\n",
        "vocabCount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n",
            "prediction shape (1, 1)\n",
            "[[0.05449035]]\n",
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "text = \"You won $100 click link below to collect\"\n",
        "processedText = clean_text(text)\n",
        "#print(processedText)\n",
        "finalText = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([processedText]), padding='pre', maxlen=171)\n",
        "prediction = model.predict(finalText)\n",
        "print(\"prediction shape\", prediction.shape)\n",
        "print(prediction)\n",
        "print(np.int(np.rint(prediction[0,0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = reg_model.predict(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1663008985510
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "# Combine scoring script & environment in Inference configuration\n",
        "inference_config = InferenceConfig(entry_script=\"09102022/score.py\",\n",
        "                                   environment=hyper_env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1663009129493
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.webservice.aci import AciWebservice\n",
        "# Set deployment configuration\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
        "                                                       memory_gb = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1663009290514
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Define the model, inference, & deployment configuration and web service name and location to deploy\n",
        "service = Model.deploy(workspace = ws,\n",
        "                       name = \"my-smsspam-service-v1\",\n",
        "                       models = [reg_model],\n",
        "                       inference_config = inference_config,\n",
        "                       deployment_config = deployment_config)\n",
        "\n",
        "service.wait_for_deployment(show_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1663009486696
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AciWebservice(workspace=Workspace.create(name='nahmed30-azureml-workspace', subscription_id='16bc73b5-82be-47f2-b5ab-f2373344794c', resource_group='epe-poc-nazeer'), name=my-smsspam-service-v1, image_id=None, image_digest=None, compute_type=ACI, state=Transitioning, scoring_uri=None, tags={}, properties={'azureml.git.repository_uri': 'https://github.com/Nazeer2013/nd00333-capstone.git', 'mlflow.source.git.repoURL': 'https://github.com/Nazeer2013/nd00333-capstone.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '5a0671ea693258335dd7d3d443969a0cb0e8c232', 'mlflow.source.git.commit': '5a0671ea693258335dd7d3d443969a0cb0e8c232', 'azureml.git.dirty': 'True'}, created_by={'userObjectId': 'a8930881-263c-498d-8975-58e6a0c28f2c', 'userPuId': '10032001567EC76C', 'userIdp': None, 'userAltSecId': None, 'userIss': 'https://sts.windows.net/db05faca-c82a-4b9d-b9c5-0f64b6755421/', 'userTenantId': 'db05faca-c82a-4b9d-b9c5-0f64b6755421', 'userName': 'Nazeer Ahmed', 'upn': 'nahmed30@optumcloud.com'})"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "service"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
