{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The \"Azure ML SDK\" for SMS Spam Inference \n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, we will show the use of Azure ML SDK to train, deploy and consume a model through Azure ML.\n",
        "\n",
        "\n",
        "Steps:\n",
        "\n",
        "1. Create a workspace. Create an Experiment in an existing Workspace.\n",
        "2. Create a Compute cluster.\n",
        "3. Load the dataset.\n",
        "4. Select and Train a model.\n",
        "5. Configure HyperDrive.\n",
        "6. Run the HyperDrive experiment usinng HyperDriveConfig.\n",
        "7. Explore the results and get the best model.\n",
        "8. Register the best model.\n",
        "9. Deploy the best model and create endpoint.\n",
        "10. Consume the endpoint.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Azure Machine Learning SDK-specific imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663299317506
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.core.model import InferenceConfig, Model\n",
        "from azureml.core.webservice import AciWebservice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Workspace\n",
        "Initialize a workspace object from persisted configuration. Make sure the config file is present at .\\config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663299318085
        }
      },
      "outputs": [],
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create an Azure ML experiment\n",
        "\n",
        "Let's create an experiment named 'aml-experiment' in the workspace we just initialized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663299318382
        }
      },
      "outputs": [],
      "source": [
        "experiment_name = 'nb_lr_exp_0920_v10'\n",
        "experiment = Experiment(ws, experiment_name)\n",
        "experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Compute Cluster\n",
        "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/concept-azure-machine-learning-architecture#compute-target) for your AutoML run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663299318683
        }
      },
      "outputs": [],
      "source": [
        "aml_name = \"cpu-cluster\"\n",
        "try:\n",
        "    aml_compute = AmlCompute(ws, aml_name)\n",
        "    print('Found existing AML compute context.')\n",
        "except:\n",
        "    print('Creating new AML compute context.')\n",
        "    aml_config = AmlCompute.provisioning_configuration(vm_size = \"Standard_D2_v2\", min_nodes=1, max_nodes=3)\n",
        "    aml_compute = AmlCompute.create(ws, name = aml_name, provisioning_configuration = aml_config)\n",
        "    aml_compute.wait_for_completion(show_output = True)\n",
        "\n",
        "cts = ws.compute_targets\n",
        "compute_target = cts[aml_name]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n",
        "Make sure you have uploaded the dataset to Azure ML and that the key is the same name as the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663299321736
        }
      },
      "outputs": [],
      "source": [
        "key = 'UdacityPrjEmailSpamDataSet'\n",
        "smsspam_ds = ws.datasets[key]\n",
        "df = smsspam_ds.to_pandas_dataframe()\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create workspace folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "experiment_folder = 'nb_lr_exp_0920_v10'\n",
        "os.makedirs(experiment_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/hyperdrive_env_v10.yml\n",
        "name: batch_environment\n",
        "dependencies:\n",
        "- python=3.8.5\n",
        "- scikit-learn\n",
        "- pandas\n",
        "- numpy\n",
        "- regex\n",
        "- nltk\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Python script to prepare the data train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/train_0920_v10.py\n",
        "\n",
        "#import libraries\n",
        "import argparse, joblib, os\n",
        "from azureml.core import Run\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import csv\n",
        "import string\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import regex as re\n",
        "\n",
        "import pickle\n",
        "import tempfile\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.dataset import Dataset\n",
        "import scipy.sparse\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import lil_matrix, csr_matrix, issparse\n",
        "import re\n",
        "\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# Get script arguments\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "# Input dataset\n",
        "parser.add_argument(\"--input-data\", type=str, dest='input_data', help='training dataset')\n",
        "\n",
        "# Hyperparameters\n",
        "#parser.add_argument('--learning_rate', type=float, dest='learning_rate', default=0.1, help='learning rate')\n",
        "# parser.add_argument('--n_estimators', type=int, dest='n_estimators', default=100, help='number of estimators')\n",
        "\n",
        "parser.add_argument('--C', type=float, default=1.0, help=\"indicates regularization\")\n",
        "parser.add_argument('--max_iter', type=int, default=50, help=\"Maximum number of iterations\")\n",
        "\n",
        "# Add arguments to args collection\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Log Hyperparameter values\n",
        "# run.log('learning_rate',  np.float(args.learning_rate))\n",
        "# run.log('n_estimators',  np.int(args.n_estimators))\n",
        "\n",
        "run.log(\"Regularization Strength:\", np.float(args.C))\n",
        "run.log(\"Max iterations:\", np.int(args.max_iter))\n",
        "\n",
        " \n",
        "# load the sms spam dataset -- Get the training data from the input\n",
        "print(\"Loading SMS Spam Data...\")\n",
        "df = run.input_datasets['training_data'].to_pandas_dataframe() \n",
        "\n",
        "#--------------------------Prepare Data-------------------------------------------------\n",
        "# Cleanup and Prepare Data # Find and eliminate stop words \n",
        "nltk.download('stopwords')\n",
        "stop_words= set(stopwords.words(\"english\"))\n",
        "stop_words.update(['https', 'http', 'amp', 'CO', 't', 'u', 'new', \"I'm\", \"would\"])\n",
        "\n",
        "\n",
        "spam = df.query(\"v1=='spam'\").v2.str.cat(sep=\" \")\n",
        "ham = df.query(\"v1=='ham'\").v2.str.cat(sep=\" \")\n",
        "\n",
        "# convert spam to 1 and ham to 0\n",
        "df = df.replace('spam', 1)\n",
        "df = df.replace('ham', 0)\n",
        "\n",
        "# Clean the text\n",
        "def clean_text(text):\n",
        "    whitespace = re.compile(r\"\\s+\")\n",
        "    web_address = re.compile(r\"(?i)http(s):\\/\\/[a-z0-9.~_\\-\\/]+\")\n",
        "    user = re.compile(r\"(?i)@[a-z0-9_]+\")\n",
        "    text = text.replace('.', '')\n",
        "    text = whitespace.sub(' ', text)\n",
        "    text = web_address.sub('', text)\n",
        "    text = user.sub('', text)\n",
        "    text = re.sub(r\"\\[[^()]*\\]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = re.sub(r'[^\\w\\s]','',text)\n",
        "    text = re.sub(r\"(?:@\\S*|#\\S*|http(?=.*://)\\S*)\", \"\", text)\n",
        "    return text.lower()\n",
        "\n",
        "df.v2 = [clean_text(item) for item in df.v2]\n",
        "\n",
        "#---------------------More Data Prep-----------#\n",
        "df = df.drop(['Column3', 'Column4', 'Column5'], axis = 1)\n",
        "\n",
        "df_msg_copy = df['v2'].copy()\n",
        "\n",
        "def text_preprocess(text):\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
        "    return \" \".join(text)\n",
        "\n",
        "df_msg_copy = df_msg_copy.apply(text_preprocess)\n",
        "\n",
        "def stemmer (text):\n",
        "    text = text.split()\n",
        "    words = \"\"\n",
        "    for i in text:\n",
        "            stemmer = SnowballStemmer(\"english\")\n",
        "            words += (stemmer.stem(i))+\" \"\n",
        "    return words\n",
        "\n",
        "df_msg_copy = df_msg_copy.apply(stemmer)\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "train_corpus = vectorizer.fit_transform(df_msg_copy)\n",
        "\n",
        "\n",
        "# Split Train and Test\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(train_corpus, df.v1, test_size=0.3, random_state=20)\n",
        "\n",
        "# --------------------------End Prepare Data--------------------------------------------\n",
        "\n",
        "\n",
        "# --------------------------Start Training----------------------------------------------\n",
        "# Train a Logistic Regression classification model without the specified hyperparameters\n",
        "print('Training a classification model')\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', penalty='l1', C=args.C, max_iter=args.max_iter )\n",
        "model.fit(xTrain, yTrain)\n",
        "pred = model.predict(xTest)\n",
        "acc = accuracy_score(yTest,pred)\n",
        "\n",
        "# ---------------------------End Training------------------------------------------------\n",
        "\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(xTest)\n",
        "auc = roc_auc_score(yTest,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# Save the model in the run outputs\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "joblib.dump(value=model, filename='outputs/model_v10.pkl')\n",
        "\n",
        "run.complete()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## HyperDrive Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#primary-metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run a hyperparameter tuning experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.train.hyperdrive import GridParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Create a Python environment for the experiment\n",
        "hyper_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/hyperdrive_env_v10.yml\")\n",
        "\n",
        "# Early termination policy\n",
        "early_termination_policy = BanditPolicy(evaluation_interval=2,slack_factor=0.2)\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='train_0920_v10.py',\n",
        "                                # Add non-hyperparameter arguments -in this case, the training dataset\n",
        "                                arguments = ['--input-data', smsspam_ds.as_named_input('training_data')],\n",
        "                                environment=hyper_env,\n",
        "                                compute_target = aml_compute)\n",
        "\n",
        "# Sample a range of parameter values\n",
        "params = GridParameterSampling(\n",
        "    {\n",
        "        # Hyperdrive will try 6 combinations, adding these as script arguments\n",
        "        '--C': choice(0.01, 0.1, 1.0),\n",
        "        '--max_iter' : choice(10, 50)\n",
        "        # '--C': choice(1.0),\n",
        "        # '--max_iter' : choice(10)\n",
        "    }\n",
        ")\n",
        "\n",
        "# Configure hyperdrive settings\n",
        "hyperdrive = HyperDriveConfig(run_config=script_config, \n",
        "                          hyperparameter_sampling=params, \n",
        "                          policy=early_termination_policy, # Banditpolicy early stopping policy\n",
        "                          primary_metric_name='Accuracy', # Find the highest AUC metric\n",
        "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
        "                          max_total_runs=36, # Restict the experiment to 6 iterations\n",
        "                          max_concurrent_runs=2) # Run up to 2 iterations in parallel\n",
        "\n",
        "# Run the experiment\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=hyperdrive)\n",
        "\n",
        "# Show the status in the notebook as the experiment runs\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Select the best performing run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print all child runs, sorted by the primary metric\n",
        "for child_run in run.get_children_sorted_by_primary_metric():\n",
        "    print(child_run)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the best run, and its metrics and arguments\n",
        "best_run = run.get_best_run_by_primary_metric()\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "script_arguments = best_run.get_details() ['runDefinition']['arguments']\n",
        "print('Best Run Id: ', best_run.id)\n",
        "print(' -AUC:', best_run_metrics['AUC'])\n",
        "print(' -Accuracy:', best_run_metrics['Accuracy'])\n",
        "print(' -Arguments:',script_arguments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register Best Model\n",
        "\n",
        "Now that you've found the best run, you can register the model it trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Register best model best model\n",
        "reg_model = best_run.register_model(model_name='sms-spam-hd-0920-v10-model',\n",
        "                                        model_path='outputs/model_v10.pkl', \n",
        "                                        tags={'Method':'LogisticRegression Hyperdrive'}, \n",
        "                                        # sample_input_dataset = smsspam_ds,\n",
        "                                        properties={'Accuracy': best_run_metrics['Accuracy'],\n",
        "                                                    'AUC': best_run_metrics['AUC']})\n",
        "print(reg_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'sms-spam-hd-0920-v10-model:2'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg_model.id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1663300879791
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run(Experiment: nb_lr_exp_0920_v10,\n",
            "Id: HD_ec2e2bbc-f3a6-4355-80ce-13d828b59e17_5,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n",
            "Run(Experiment: nb_lr_exp_0920_v10,\n",
            "Id: HD_ec2e2bbc-f3a6-4355-80ce-13d828b59e17_4,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n",
            "Run(Experiment: nb_lr_exp_0920_v10,\n",
            "Id: HD_ec2e2bbc-f3a6-4355-80ce-13d828b59e17_2,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n",
            "Run(Experiment: nb_lr_exp_0920_v10,\n",
            "Id: HD_ec2e2bbc-f3a6-4355-80ce-13d828b59e17_3,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n",
            "Run(Experiment: nb_lr_exp_0920_v10,\n",
            "Id: HD_ec2e2bbc-f3a6-4355-80ce-13d828b59e17_1,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n",
            "Run(Experiment: nb_lr_exp_0920_v10,\n",
            "Id: HD_ec2e2bbc-f3a6-4355-80ce-13d828b59e17_0,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for child_run in run.get_children():\n",
        "    print(child_run,\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'sms-spam-hd-0920-v10-model'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg_model.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1663300880215
        }
      },
      "outputs": [],
      "source": [
        "model_name = reg_model.name\n",
        "script_file = \"scripts/score_v10.py\"\n",
        "description = \"aml SMS spam lr hd project sdk\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1663300881569
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.automl.core.shared import constants\n",
        "env = best_run.get_environment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy Model as Webservice on Azure Container Instance\n",
        "\n",
        "Run the following code to deploy the best model. You can see the state of the deployment in the Azure ML portal. This step can take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "inference_config = InferenceConfig(entry_script=script_file, environment=best_run.get_environment())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "InferenceConfig(entry_script=scripts/score_v10.py, runtime=None, conda_file=None, extra_docker_file_steps=None, source_directory=None, enable_gpu=None, base_image=None, base_image_registry=<azureml.core.container_registry.ContainerRegistry object at 0x7fbf6d9b42b0>)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inference_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
        "                                               memory_gb = 1,\n",
        "                                               tags = {'type': \"automl-SMS-spam-prediction\"},\n",
        "                                               description = 'Sample service for AutoML SMS Spam Prediction')\n",
        "\n",
        "aci_service_name = 'smsspam-lrhd-v10-7'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Web Service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1663301113175
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2022-09-21 03:26:32-04:00 Creating Container Registry if not exists.\n",
            "2022-09-21 03:26:32-04:00 Registering the environment.\n",
            "2022-09-21 03:26:33-04:00 Use the existing image.\n",
            "2022-09-21 03:26:34-04:00 Submitting deployment to compute.\n",
            "2022-09-21 03:26:39-04:00 Checking the status of deployment smsspam-lrhd-v10-7..\n",
            "2022-09-21 03:28:46-04:00 Checking the status of inference endpoint smsspam-lrhd-v10-7.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n",
            "Healthy\n"
          ]
        }
      ],
      "source": [
        "aci_service = Model.deploy(ws, aci_service_name, [reg_model], inference_config, aciconfig)\n",
        "aci_service.wait_for_deployment(True)\n",
        "print(aci_service.state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Service test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***REST Endpoint***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://f179cabe-8ce5-48b1-b153-924873c6816b.centralus.azurecontainer.io/score\n"
          ]
        }
      ],
      "source": [
        "scoring_url=aci_service.scoring_uri\n",
        "print(scoring_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'\"{\\\\\"result\\\\\": [0]}\"'\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import os\n",
        "import ssl\n",
        "\n",
        "def allowSelfSignedHttps(allowed):\n",
        "    # bypass the server certificate verification on client side\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
        "\n",
        "# Request data goes here\n",
        "# The example below assumes JSON formatting which may be updated\n",
        "# depending on the format your endpoint expects.\n",
        "# More information can be found here:\n",
        "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
        "\n",
        "data =  {\n",
        "  \"data\": [\n",
        "    {\n",
        "      \"v2\": \"Is that seriously how you spell his name\"\n",
        "    }\n",
        "  ],\n",
        "  \"method\": \"predict\"\n",
        "}\n",
        "\n",
        "body = str.encode(json.dumps(data))\n",
        "\n",
        "# url = 'http://85c032ba-bdb1-4060-801d-cd7a6bc543a8.centralus.azurecontainer.io/score'\n",
        "url = scoring_url\n",
        "api_key = '' # Replace this with the API key for the web service\n",
        "\n",
        "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
        "# Remove this header to have the request observe the endpoint traffic rules\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
        "\n",
        "req = urllib.request.Request(url, body, headers)\n",
        "\n",
        "try:\n",
        "    response = urllib.request.urlopen(req)\n",
        "\n",
        "    result = response.read()\n",
        "    print(result)\n",
        "except urllib.error.HTTPError as error:\n",
        "    print(\"The request failed with status code: \" + str(error.code))\n",
        "\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
        "    print(error.info())\n",
        "    print(error.read().decode(\"utf8\", 'ignore'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'\"{\\\\\"result\\\\\": [1]}\"'\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import os\n",
        "import ssl\n",
        "\n",
        "def allowSelfSignedHttps(allowed):\n",
        "    # bypass the server certificate verification on client side\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
        "\n",
        "# Request data goes here\n",
        "# The example below assumes JSON formatting which may be updated\n",
        "# depending on the format your endpoint expects.\n",
        "# More information can be found here:\n",
        "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
        "\n",
        "data =  {\n",
        "  \"data\": [\n",
        "    {\n",
        "      \"v2\": \"XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here\"\n",
        "    }\n",
        "  ],\n",
        "  \"method\": \"predict\"\n",
        "}\n",
        "\n",
        "body = str.encode(json.dumps(data))\n",
        "\n",
        "# url = 'http://85c032ba-bdb1-4060-801d-cd7a6bc543a8.centralus.azurecontainer.io/score'\n",
        "url = scoring_url\n",
        "api_key = '' # Replace this with the API key for the web service\n",
        "\n",
        "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
        "# Remove this header to have the request observe the endpoint traffic rules\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
        "\n",
        "req = urllib.request.Request(url, body, headers)\n",
        "\n",
        "try:\n",
        "    response = urllib.request.urlopen(req)\n",
        "\n",
        "    result = response.read()\n",
        "    print(result)\n",
        "except urllib.error.HTTPError as error:\n",
        "    print(\"The request failed with status code: \" + str(error.code))\n",
        "\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
        "    print(error.info())\n",
        "    print(error.read().decode(\"utf8\", 'ignore'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Delete Service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method Webservice.delete of AciWebservice(workspace=Workspace.create(name='nahmed30-azureml-workspace', subscription_id='16bc73b5-82be-47f2-b5ab-f2373344794c', resource_group='epe-poc-nazeer'), name=smsspam-lrhd-v10-7, image_id=None, image_digest=None, compute_type=ACI, state=Healthy, scoring_uri=http://f179cabe-8ce5-48b1-b153-924873c6816b.centralus.azurecontainer.io/score, tags={'type': 'automl-SMS-spam-prediction'}, properties={'azureml.git.repository_uri': 'https://github.com/Nazeer2013/nd00333-capstone.git', 'mlflow.source.git.repoURL': 'https://github.com/Nazeer2013/nd00333-capstone.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '12f6fc1128f76313f7a9bff2fc986fb76046de43', 'mlflow.source.git.commit': '12f6fc1128f76313f7a9bff2fc986fb76046de43', 'azureml.git.dirty': 'True', 'hasInferenceSchema': 'True', 'hasHttps': 'False', 'authEnabled': 'False'}, created_by={'userObjectId': 'a8930881-263c-498d-8975-58e6a0c28f2c', 'userPuId': '10032001567EC76C', 'userIdp': None, 'userAltSecId': None, 'userIss': 'https://sts.windows.net/db05faca-c82a-4b9d-b9c5-0f64b6755421/', 'userTenantId': 'db05faca-c82a-4b9d-b9c5-0f64b6755421', 'userName': 'Nazeer Ahmed', 'upn': 'nahmed30@optumcloud.com'})>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aci_service.delete"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
