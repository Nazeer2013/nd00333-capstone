{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The \"Azure ML SDK\" for SMS Spam Inference \n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, we will show the use of Azure ML SDK to train, deploy and consume a model through Azure ML.\n",
        "\n",
        "\n",
        "Steps:\n",
        "\n",
        "1. Create a workspace. Create an Experiment in an existing Workspace.\n",
        "2. Create a Compute cluster.\n",
        "3. Load the dataset.\n",
        "4. Select and Train a model.\n",
        "5. Configure HyperDrive.\n",
        "6. Run the HyperDrive experiment usinng HyperDriveConfig.\n",
        "7. Explore the results and get the best model.\n",
        "8. Register the best model.\n",
        "9. Deploy the best model and create endpoint.\n",
        "10. Consume the endpoint.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Azure Machine Learning SDK-specific imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1663299317506
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.core.model import InferenceConfig, Model\n",
        "from azureml.core.webservice import AciWebservice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Workspace\n",
        "Initialize a workspace object from persisted configuration. Make sure the config file is present at .\\config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1663299318085
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nahmed30-azureml-workspace\n",
            "epe-poc-nazeer\n",
            "centralus\n",
            "16bc73b5-82be-47f2-b5ab-f2373344794c\n"
          ]
        }
      ],
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create an Azure ML experiment\n",
        "\n",
        "Let's create an experiment named 'aml-experiment' in the workspace we just initialized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1663299318382
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>nb_lr_exp_0920_v10</td><td>nahmed30-azureml-workspace</td><td><a href=\"https://ml.azure.com/experiments/id/145483ca-f055-41fa-a0a7-4213bccae04f?wsid=/subscriptions/16bc73b5-82be-47f2-b5ab-f2373344794c/resourcegroups/epe-poc-nazeer/workspaces/nahmed30-azureml-workspace&amp;tid=db05faca-c82a-4b9d-b9c5-0f64b6755421\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Experiment(Name: nb_lr_exp_0920_v10,\n",
              "Workspace: nahmed30-azureml-workspace)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "experiment_name = 'nb_lr_exp_0920_v10'\n",
        "experiment = Experiment(ws, experiment_name)\n",
        "experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Compute Cluster\n",
        "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/concept-azure-machine-learning-architecture#compute-target) for your AutoML run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1663299318683
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing AML compute context.\n"
          ]
        }
      ],
      "source": [
        "aml_name = \"cpu-cluster\"\n",
        "try:\n",
        "    aml_compute = AmlCompute(ws, aml_name)\n",
        "    print('Found existing AML compute context.')\n",
        "except:\n",
        "    print('Creating new AML compute context.')\n",
        "    aml_config = AmlCompute.provisioning_configuration(vm_size = \"Standard_D2_v2\", min_nodes=1, max_nodes=3)\n",
        "    aml_compute = AmlCompute.create(ws, name = aml_name, provisioning_configuration = aml_config)\n",
        "    aml_compute.wait_for_completion(show_output = True)\n",
        "\n",
        "cts = ws.compute_targets\n",
        "compute_target = cts[aml_name]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n",
        "Make sure you have uploaded the dataset to Azure ML and that the key is the same name as the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1663299321736
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Column3</th>\n",
              "      <th>Column4</th>\n",
              "      <th>Column5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5572</td>\n",
              "      <td>5572</td>\n",
              "      <td>50</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2</td>\n",
              "      <td>5169</td>\n",
              "      <td>43</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>ham</td>\n",
              "      <td>Sorry, I'll call later</td>\n",
              "      <td>bt not his girlfrnd... G o o d n i g h t . . .@\"</td>\n",
              "      <td>MK17 92H. 450Ppw 16\"</td>\n",
              "      <td>GNT:-)\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>4825</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          v1                      v2  \\\n",
              "count   5572                    5572   \n",
              "unique     2                    5169   \n",
              "top      ham  Sorry, I'll call later   \n",
              "freq    4825                      30   \n",
              "\n",
              "                                                  Column3  \\\n",
              "count                                                  50   \n",
              "unique                                                 43   \n",
              "top      bt not his girlfrnd... G o o d n i g h t . . .@\"   \n",
              "freq                                                    3   \n",
              "\n",
              "                      Column4  Column5  \n",
              "count                      12        6  \n",
              "unique                     10        5  \n",
              "top      MK17 92H. 450Ppw 16\"  GNT:-)\"  \n",
              "freq                        2        2  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "key = 'UdacityPrjEmailSpamDataSet'\n",
        "smsspam_ds = ws.datasets[key]\n",
        "df = smsspam_ds.to_pandas_dataframe()\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create workspace folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "experiment_folder = 'nb_lr_exp_0920_v10'\n",
        "os.makedirs(experiment_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing nb_lr_exp_0920_v10/hyperdrive_env_v10.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile $experiment_folder/hyperdrive_env_v10.yml\n",
        "name: batch_environment\n",
        "dependencies:\n",
        "- python=3.8.5\n",
        "- scikit-learn\n",
        "- pandas\n",
        "- numpy\n",
        "- regex\n",
        "- nltk\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Python script to prepare the data train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing nb_lr_exp_0920_v10/train_0920_v10.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $experiment_folder/train_0920_v10.py\n",
        "\n",
        "#import libraries\n",
        "import argparse, joblib, os\n",
        "from azureml.core import Run\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import csv\n",
        "import string\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import regex as re\n",
        "\n",
        "import pickle\n",
        "import tempfile\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.dataset import Dataset\n",
        "import scipy.sparse\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import lil_matrix, csr_matrix, issparse\n",
        "import re\n",
        "\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# Get script arguments\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "# Input dataset\n",
        "parser.add_argument(\"--input-data\", type=str, dest='input_data', help='training dataset')\n",
        "\n",
        "# Hyperparameters\n",
        "#parser.add_argument('--learning_rate', type=float, dest='learning_rate', default=0.1, help='learning rate')\n",
        "# parser.add_argument('--n_estimators', type=int, dest='n_estimators', default=100, help='number of estimators')\n",
        "\n",
        "parser.add_argument('--C', type=float, default=1.0, help=\"indicates regularization\")\n",
        "parser.add_argument('--max_iter', type=int, default=50, help=\"Maximum number of iterations\")\n",
        "\n",
        "# Add arguments to args collection\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Log Hyperparameter values\n",
        "# run.log('learning_rate',  np.float(args.learning_rate))\n",
        "# run.log('n_estimators',  np.int(args.n_estimators))\n",
        "\n",
        "run.log(\"Regularization Strength:\", np.float(args.C))\n",
        "run.log(\"Max iterations:\", np.int(args.max_iter))\n",
        "\n",
        " \n",
        "# load the sms spam dataset -- Get the training data from the input\n",
        "print(\"Loading SMS Spam Data...\")\n",
        "df = run.input_datasets['training_data'].to_pandas_dataframe() \n",
        "\n",
        "#--------------------------Prepare Data-------------------------------------------------\n",
        "# Cleanup and Prepare Data # Find and eliminate stop words \n",
        "nltk.download('stopwords')\n",
        "stop_words= set(stopwords.words(\"english\"))\n",
        "stop_words.update(['https', 'http', 'amp', 'CO', 't', 'u', 'new', \"I'm\", \"would\"])\n",
        "\n",
        "\n",
        "spam = df.query(\"v1=='spam'\").v2.str.cat(sep=\" \")\n",
        "ham = df.query(\"v1=='ham'\").v2.str.cat(sep=\" \")\n",
        "\n",
        "# convert spam to 1 and ham to 0\n",
        "df = df.replace('spam', 1)\n",
        "df = df.replace('ham', 0)\n",
        "\n",
        "# Clean the text\n",
        "def clean_text(text):\n",
        "    whitespace = re.compile(r\"\\s+\")\n",
        "    web_address = re.compile(r\"(?i)http(s):\\/\\/[a-z0-9.~_\\-\\/]+\")\n",
        "    user = re.compile(r\"(?i)@[a-z0-9_]+\")\n",
        "    text = text.replace('.', '')\n",
        "    text = whitespace.sub(' ', text)\n",
        "    text = web_address.sub('', text)\n",
        "    text = user.sub('', text)\n",
        "    text = re.sub(r\"\\[[^()]*\\]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = re.sub(r'[^\\w\\s]','',text)\n",
        "    text = re.sub(r\"(?:@\\S*|#\\S*|http(?=.*://)\\S*)\", \"\", text)\n",
        "    return text.lower()\n",
        "\n",
        "df.v2 = [clean_text(item) for item in df.v2]\n",
        "\n",
        "#---------------------More Data Prep-----------#\n",
        "df = df.drop(['Column3', 'Column4', 'Column5'], axis = 1)\n",
        "\n",
        "df_msg_copy = df['v2'].copy()\n",
        "\n",
        "def text_preprocess(text):\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
        "    return \" \".join(text)\n",
        "\n",
        "df_msg_copy = df_msg_copy.apply(text_preprocess)\n",
        "\n",
        "def stemmer (text):\n",
        "    text = text.split()\n",
        "    words = \"\"\n",
        "    for i in text:\n",
        "            stemmer = SnowballStemmer(\"english\")\n",
        "            words += (stemmer.stem(i))+\" \"\n",
        "    return words\n",
        "\n",
        "df_msg_copy = df_msg_copy.apply(stemmer)\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "train_corpus = vectorizer.fit_transform(df_msg_copy)\n",
        "\n",
        "\n",
        "# Split Train and Test\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(train_corpus, df.v1, test_size=0.3, random_state=20)\n",
        "\n",
        "# --------------------------End Prepare Data--------------------------------------------\n",
        "\n",
        "\n",
        "# --------------------------Start Training----------------------------------------------\n",
        "# Train a Logistic Regression classification model without the specified hyperparameters\n",
        "print('Training a classification model')\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', penalty='l1', C=args.C, max_iter=args.max_iter )\n",
        "model.fit(xTrain, yTrain)\n",
        "pred = model.predict(xTest)\n",
        "acc = accuracy_score(yTest,pred)\n",
        "\n",
        "# ---------------------------End Training------------------------------------------------\n",
        "\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(xTest)\n",
        "auc = roc_auc_score(yTest,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# Save the model in the run outputs\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "joblib.dump(value=model, filename='outputs/model_v10.pkl')\n",
        "\n",
        "run.complete()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## HyperDrive Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#primary-metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run a hyperparameter tuning experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'runId': 'HD_69bf5dbd-ef57-4c08-82e2-996ff6475271',\n",
              " 'target': 'cpu-cluster',\n",
              " 'status': 'Completed',\n",
              " 'startTimeUtc': '2022-09-21T03:12:58.998907Z',\n",
              " 'endTimeUtc': '2022-09-21T03:18:02.955953Z',\n",
              " 'services': {},\n",
              " 'properties': {'primary_metric_config': '{\"name\":\"Accuracy\",\"goal\":\"maximize\"}',\n",
              "  'resume_from': 'null',\n",
              "  'runTemplate': 'HyperDrive',\n",
              "  'azureml.runsource': 'hyperdrive',\n",
              "  'platform': 'AML',\n",
              "  'ContentSnapshotId': 'd79f8f0c-3241-4105-b62d-54cbea2547da',\n",
              "  'user_agent': 'python/3.8.12 (macOS-10.15.7-x86_64-i386-64bit) msrest/0.6.21 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.44.0',\n",
              "  'space_size': '6',\n",
              "  'score': '0.9503588516746412',\n",
              "  'best_child_run_id': 'HD_69bf5dbd-ef57-4c08-82e2-996ff6475271_4',\n",
              "  'best_metric_status': 'Succeeded',\n",
              "  'best_data_container_id': 'dcid.HD_69bf5dbd-ef57-4c08-82e2-996ff6475271_4'},\n",
              " 'inputDatasets': [],\n",
              " 'outputDatasets': [],\n",
              " 'runDefinition': {'configuration': None,\n",
              "  'attribution': None,\n",
              "  'telemetryValues': {'amlClientType': 'azureml-sdk-train',\n",
              "   'amlClientModule': '[Scrubbed]',\n",
              "   'amlClientFunction': '[Scrubbed]',\n",
              "   'tenantId': 'db05faca-c82a-4b9d-b9c5-0f64b6755421',\n",
              "   'amlClientRequestId': '910ffef2-9875-4c88-ac97-b74a29462a61',\n",
              "   'amlClientSessionId': 'cd118689-1a85-469e-ae3e-fb1c35f2caf3',\n",
              "   'subscriptionId': '16bc73b5-82be-47f2-b5ab-f2373344794c',\n",
              "   'estimator': 'NoneType',\n",
              "   'samplingMethod': 'GRID',\n",
              "   'terminationPolicy': 'Default',\n",
              "   'primaryMetricGoal': 'maximize',\n",
              "   'maxTotalRuns': 36,\n",
              "   'maxConcurrentRuns': 2,\n",
              "   'maxDurationMinutes': 10080,\n",
              "   'vmSize': None},\n",
              "  'snapshotId': 'd79f8f0c-3241-4105-b62d-54cbea2547da',\n",
              "  'snapshots': [],\n",
              "  'sourceCodeDataReference': None,\n",
              "  'parentRunId': None,\n",
              "  'dataContainerId': None,\n",
              "  'runType': None,\n",
              "  'displayName': None,\n",
              "  'environmentAssetId': None,\n",
              "  'properties': {},\n",
              "  'tags': {},\n",
              "  'aggregatedArtifactPath': None},\n",
              " 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://nahmed30storage.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_69bf5dbd-ef57-4c08-82e2-996ff6475271/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=j8G47a0GeWQ%2BgFv21DCRZmS7N5wsNub9ZqeViThwcPU%3D&skoid=990e57a2-6b09-4324-b33f-71ef714de994&sktid=db05faca-c82a-4b9d-b9c5-0f64b6755421&skt=2022-09-21T02%3A29%3A01Z&ske=2022-09-22T10%3A39%3A01Z&sks=b&skv=2019-07-07&st=2022-09-21T03%3A08%3A11Z&se=2022-09-21T11%3A18%3A11Z&sp=r'},\n",
              " 'submittedBy': 'Nazeer Ahmed'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.train.hyperdrive import GridParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Create a Python environment for the experiment\n",
        "hyper_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/hyperdrive_env_v10.yml\")\n",
        "\n",
        "# Get the training dataset\n",
        "# diabetes_ds = ws.datasets.get(\"sms spam dataset\")\n",
        "# dataset\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='train_0920_v10.py',\n",
        "                                # Add non-hyperparameter arguments -in this case, the training dataset\n",
        "                                arguments = ['--input-data', smsspam_ds.as_named_input('training_data')],\n",
        "                                environment=hyper_env,\n",
        "                                compute_target = aml_compute)\n",
        "\n",
        "# Sample a range of parameter values\n",
        "params = GridParameterSampling(\n",
        "    {\n",
        "        # Hyperdrive will try 6 combinations, adding these as script arguments\n",
        "        '--C': choice(0.01, 0.1, 1.0),\n",
        "        '--max_iter' : choice(10, 50)\n",
        "        # '--C': choice(1.0),\n",
        "        # '--max_iter' : choice(10)\n",
        "    }\n",
        ")\n",
        "\n",
        "# Configure hyperdrive settings\n",
        "hyperdrive = HyperDriveConfig(run_config=script_config, \n",
        "                          hyperparameter_sampling=params, \n",
        "                          policy=None, # No early stopping policy\n",
        "                          primary_metric_name='Accuracy', # Find the highest AUC metric\n",
        "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
        "                          max_total_runs=36, # Restict the experiment to 6 iterations\n",
        "                          max_concurrent_runs=2) # Run up to 2 iterations in parallel\n",
        "\n",
        "# Run the experiment\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=hyperdrive)\n",
        "\n",
        "# Show the status in the notebook as the experiment runs\n",
        "# RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Select the best performing run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'run_id': 'HD_69bf5dbd-ef57-4c08-82e2-996ff6475271_4', 'hyperparameters': '{\"--C\": 1.0, \"--max_iter\": 10}', 'best_primary_metric': 0.9503588516746412, 'status': 'Completed'}\n",
            "{'run_id': 'HD_69bf5dbd-ef57-4c08-82e2-996ff6475271_5', 'hyperparameters': '{\"--C\": 1.0, \"--max_iter\": 50}', 'best_primary_metric': 0.9497607655502392, 'status': 'Completed'}\n",
            "{'run_id': 'HD_69bf5dbd-ef57-4c08-82e2-996ff6475271_3', 'hyperparameters': '{\"--C\": 0.1, \"--max_iter\": 50}', 'best_primary_metric': 0.8726076555023924, 'status': 'Completed'}\n",
            "{'run_id': 'HD_69bf5dbd-ef57-4c08-82e2-996ff6475271_2', 'hyperparameters': '{\"--C\": 0.1, \"--max_iter\": 10}', 'best_primary_metric': 0.8726076555023924, 'status': 'Completed'}\n",
            "{'run_id': 'HD_69bf5dbd-ef57-4c08-82e2-996ff6475271_0', 'hyperparameters': '{\"--C\": 0.01, \"--max_iter\": 10}', 'best_primary_metric': 0.8606459330143541, 'status': 'Completed'}\n",
            "{'run_id': 'HD_69bf5dbd-ef57-4c08-82e2-996ff6475271_1', 'hyperparameters': '{\"--C\": 0.01, \"--max_iter\": 50}', 'best_primary_metric': 0.8606459330143541, 'status': 'Completed'}\n"
          ]
        }
      ],
      "source": [
        "# Print all child runs, sorted by the primary metric\n",
        "for child_run in run.get_children_sorted_by_primary_metric():\n",
        "    print(child_run)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Run Id:  HD_69bf5dbd-ef57-4c08-82e2-996ff6475271_4\n",
            " -AUC: 0.9522677586664559\n",
            " -Accuracy: 0.9503588516746412\n",
            " -Arguments: ['--input-data', 'DatasetConsumptionConfig:training_data', '--C', '1', '--max_iter', '10']\n"
          ]
        }
      ],
      "source": [
        "# Get the best run, and its metrics and arguments\n",
        "best_run = run.get_best_run_by_primary_metric()\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "script_arguments = best_run.get_details() ['runDefinition']['arguments']\n",
        "print('Best Run Id: ', best_run.id)\n",
        "print(' -AUC:', best_run_metrics['AUC'])\n",
        "print(' -Accuracy:', best_run_metrics['Accuracy'])\n",
        "print(' -Arguments:',script_arguments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register Best Model\n",
        "\n",
        "Now that you've found the best run, you can register the model it trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model(workspace=Workspace.create(name='nahmed30-azureml-workspace', subscription_id='16bc73b5-82be-47f2-b5ab-f2373344794c', resource_group='epe-poc-nazeer'), name=sms-spam-hd-0920-v10-model, id=sms-spam-hd-0920-v10-model:1, version=1, tags={'Method': 'LogisticRegression Hyperdrive'}, properties={'Accuracy': '0.9503588516746412', 'AUC': '0.9522677586664559'})\n"
          ]
        }
      ],
      "source": [
        "# Register best model best model\n",
        "reg_model = best_run.register_model(model_name='sms-spam-hd-0920-v10-model',\n",
        "                                        model_path='outputs/model_v10.pkl', \n",
        "                                        tags={'Method':'LogisticRegression Hyperdrive'}, \n",
        "                                        # sample_input_dataset = smsspam_ds,\n",
        "                                        properties={'Accuracy': best_run_metrics['Accuracy'],\n",
        "                                                    'AUC': best_run_metrics['AUC']})\n",
        "print(reg_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'sms-spam-hd-0920-v10-model:1'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg_model.id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1663300879791
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run(Experiment: nb_lr_exp_0920_v10,\n",
            "Id: HD_69bf5dbd-ef57-4c08-82e2-996ff6475271_5,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n",
            "Run(Experiment: nb_lr_exp_0920_v10,\n",
            "Id: HD_69bf5dbd-ef57-4c08-82e2-996ff6475271_4,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n",
            "Run(Experiment: nb_lr_exp_0920_v10,\n",
            "Id: HD_69bf5dbd-ef57-4c08-82e2-996ff6475271_3,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n",
            "Run(Experiment: nb_lr_exp_0920_v10,\n",
            "Id: HD_69bf5dbd-ef57-4c08-82e2-996ff6475271_2,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n",
            "Run(Experiment: nb_lr_exp_0920_v10,\n",
            "Id: HD_69bf5dbd-ef57-4c08-82e2-996ff6475271_0,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n",
            "Run(Experiment: nb_lr_exp_0920_v10,\n",
            "Id: HD_69bf5dbd-ef57-4c08-82e2-996ff6475271_1,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for child_run in run.get_children():\n",
        "    print(child_run,\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'sms-spam-hd-0920-v10-model'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg_model.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "gather": {
          "logged": 1663300880215
        }
      },
      "outputs": [],
      "source": [
        "model_name = reg_model.name\n",
        "script_file = \"scripts/score_v10.py\"\n",
        "description = \"aml SMS spam lr hd project sdk\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1663300881569
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.automl.core.shared import constants\n",
        "env = best_run.get_environment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy Model as Webservice on Azure Container Instance\n",
        "\n",
        "Run the following code to deploy the best model. You can see the state of the deployment in the Azure ML portal. This step can take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "inference_config = InferenceConfig(entry_script=script_file, environment=best_run.get_environment())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "InferenceConfig(entry_script=scripts/score_v10.py, runtime=None, conda_file=None, extra_docker_file_steps=None, source_directory=None, enable_gpu=None, base_image=None, base_image_registry=<azureml.core.container_registry.ContainerRegistry object at 0x7fd3d4c6adc0>)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inference_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
        "                                               memory_gb = 1,\n",
        "                                               tags = {'type': \"automl-SMS-spam-prediction\"},\n",
        "                                               description = 'Sample service for AutoML SMS Spam Prediction')\n",
        "\n",
        "aci_service_name = 'smsspam-lrhd-v10-5'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Web Service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1663301113175
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2022-09-20 23:59:03-04:00 Creating Container Registry if not exists.\n",
            "2022-09-20 23:59:03-04:00 Registering the environment.\n",
            "2022-09-20 23:59:04-04:00 Use the existing image.\n",
            "2022-09-20 23:59:04-04:00 Generating deployment configuration.\n",
            "2022-09-20 23:59:04-04:00 Submitting deployment to compute.\n",
            "2022-09-20 23:59:09-04:00 Checking the status of deployment smsspam-lrhd-v10-4..\n",
            "2022-09-21 00:01:06-04:00 Checking the status of inference endpoint smsspam-lrhd-v10-4.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n",
            "Healthy\n"
          ]
        }
      ],
      "source": [
        "aci_service = Model.deploy(ws, aci_service_name, [reg_model], inference_config, aciconfig)\n",
        "aci_service.wait_for_deployment(True)\n",
        "print(aci_service.state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Service test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***REST Endpoint***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://1f628456-ccce-4643-9f38-05ce7044bd4f.centralus.azurecontainer.io/score\n"
          ]
        }
      ],
      "source": [
        "scoring_url=aci_service.scoring_uri\n",
        "print(scoring_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'\"{\\\\\"result\\\\\": [0]}\"'\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import os\n",
        "import ssl\n",
        "\n",
        "def allowSelfSignedHttps(allowed):\n",
        "    # bypass the server certificate verification on client side\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
        "\n",
        "# Request data goes here\n",
        "# The example below assumes JSON formatting which may be updated\n",
        "# depending on the format your endpoint expects.\n",
        "# More information can be found here:\n",
        "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
        "\n",
        "data =  {\n",
        "  \"data\": [\n",
        "    {\n",
        "      \"v2\": \"Is that seriously how you spell his name\"\n",
        "    }\n",
        "  ],\n",
        "  \"method\": \"predict\"\n",
        "}\n",
        "\n",
        "body = str.encode(json.dumps(data))\n",
        "\n",
        "# url = 'http://85c032ba-bdb1-4060-801d-cd7a6bc543a8.centralus.azurecontainer.io/score'\n",
        "url = scoring_url\n",
        "api_key = '' # Replace this with the API key for the web service\n",
        "\n",
        "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
        "# Remove this header to have the request observe the endpoint traffic rules\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
        "\n",
        "req = urllib.request.Request(url, body, headers)\n",
        "\n",
        "try:\n",
        "    response = urllib.request.urlopen(req)\n",
        "\n",
        "    result = response.read()\n",
        "    print(result)\n",
        "except urllib.error.HTTPError as error:\n",
        "    print(\"The request failed with status code: \" + str(error.code))\n",
        "\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
        "    print(error.info())\n",
        "    print(error.read().decode(\"utf8\", 'ignore'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'\"{\\\\\"result\\\\\": [1]}\"'\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import os\n",
        "import ssl\n",
        "\n",
        "def allowSelfSignedHttps(allowed):\n",
        "    # bypass the server certificate verification on client side\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
        "\n",
        "# Request data goes here\n",
        "# The example below assumes JSON formatting which may be updated\n",
        "# depending on the format your endpoint expects.\n",
        "# More information can be found here:\n",
        "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
        "\n",
        "data =  {\n",
        "  \"data\": [\n",
        "    {\n",
        "      \"v2\": \"XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here\"\n",
        "    }\n",
        "  ],\n",
        "  \"method\": \"predict\"\n",
        "}\n",
        "\n",
        "body = str.encode(json.dumps(data))\n",
        "\n",
        "# url = 'http://85c032ba-bdb1-4060-801d-cd7a6bc543a8.centralus.azurecontainer.io/score'\n",
        "url = scoring_url\n",
        "api_key = '' # Replace this with the API key for the web service\n",
        "\n",
        "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
        "# Remove this header to have the request observe the endpoint traffic rules\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
        "\n",
        "req = urllib.request.Request(url, body, headers)\n",
        "\n",
        "try:\n",
        "    response = urllib.request.urlopen(req)\n",
        "\n",
        "    result = response.read()\n",
        "    print(result)\n",
        "except urllib.error.HTTPError as error:\n",
        "    print(\"The request failed with status code: \" + str(error.code))\n",
        "\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
        "    print(error.info())\n",
        "    print(error.read().decode(\"utf8\", 'ignore'))\n"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
