{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tune Hyperparameters\n",
        "\n",
        "There are many machine learning algorithms that require *hyperparameters* (parameter values that influence training, but can't be determined from the training data itself). For example, when training a logistic regression model, you can use a *regularization rate* hyperparameter to counteract bias in the model; or when training a convolutional neural network, you can use hyperparameters like *learning rate* and *batch size* to control how weights are adjusted and how many data items are processed in a mini-batch respectively. The choice of hyperparameter values can significantly affect the performance of a trained model, or the time taken to train it; and often you need to try multiple combinations to find the optimal solution.\n",
        "\n",
        "In this case, you'll train a classification model with two hyperparameters, but the principles apply to any kind of model you can train with Azure Machine Learning."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "To get started, connect to your workspace.\n",
        "\n",
        "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import csv\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import pkg_resources\n",
        "\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import pydot\n",
        "import graphviz\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "# Check core SDK version number\n",
        "# print(\"SDK version:\", azureml.core.VERSION)\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))\n",
        "\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n",
        "\n",
        "print(\"Tensorflow version: \", tf.__version__)\n",
        "print(\"Current DateTime: \", datetime.now(pytz.timezone(\"America/New_York\")).strftime(\"%m/%d/%Y %H:%M:%S\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.41.0 to work with nahmed30-azureml-workspace\nnahmed30-azureml-workspace\nepe-poc-nazeer\ncentralus\n16bc73b5-82be-47f2-b5ab-f2373344794c\nTensorflow version:  2.2.0\nCurrent DateTime:  08/28/2022 00:18:00\n"
        }
      ],
      "execution_count": 47,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1661660281447
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch"
      ],
      "outputs": [],
      "execution_count": 50,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661660346301
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data\n",
        "\n",
        "In this lab, you'll use a dataset containing details of diabetes patients. Run the cell below to create this dataset (if it already exists, the existing version will be used)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "# Try to load the dataset from the Workspace. Otherwise, create it from the file\n",
        "# NOTE: update the key to match the dataset name\n",
        "found = False\n",
        "key = \"UdacityPrjEmailSpamDataSet\"\n",
        "description_text = \"Spam Detection DataSet for Udacity Capstone Proj \"\n",
        "\n",
        "dataset = None\n",
        "if key in ws.datasets.keys(): \n",
        "        found = True\n",
        "        dataset = ws.datasets[key] \n",
        "\n",
        "\n",
        "\n",
        "df = dataset.to_pandas_dataframe()\n",
        "df.describe()\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 51,
          "data": {
            "text/plain": "          v1                      v2  \\\ncount   5572                    5572   \nunique     2                    5169   \ntop      ham  Sorry, I'll call later   \nfreq    4825                      30   \n\n                                                  Column3 Column4  Column5  \ncount                                                  50      12        6  \nunique                                                 43      10        5  \ntop      bt not his girlfrnd... G o o d n i g h t . . .@\"      GE  GNT:-)\"  \nfreq                                                    3       2        2  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>Column3</th>\n      <th>Column4</th>\n      <th>Column5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5572</td>\n      <td>5572</td>\n      <td>50</td>\n      <td>12</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2</td>\n      <td>5169</td>\n      <td>43</td>\n      <td>10</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>ham</td>\n      <td>Sorry, I'll call later</td>\n      <td>bt not his girlfrnd... G o o d n i g h t . . .@\"</td>\n      <td>GE</td>\n      <td>GNT:-)\"</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>4825</td>\n      <td>30</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 51,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661660521696
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare a training script\n",
        "\n",
        "Now let's create a folder for the training script you'll use to train the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a name for the run history container in the workspace.\n",
        "# NOTE: update these to match your existing experiment name\n",
        "experiment_folder = 'spam_training-hyperdrive'\n",
        "experiment_name = 'ml-spam-experiment-prjassign1'\n",
        "project_folder = 'spam_training-hyperdrive'\n",
        "\n",
        "os.makedirs(project_folder, exist_ok=True)\n",
        "\n",
        "print('Project Folder is ready.')\n",
        "\n",
        "experiment = Experiment(ws, experiment_name)\n",
        "experiment"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Project Folder is ready.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 52,
          "data": {
            "text/plain": "Experiment(Name: ml-spam-experiment-prjassign1,\nWorkspace: nahmed30-azureml-workspace)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>ml-spam-experiment-prjassign1</td><td>nahmed30-azureml-workspace</td><td><a href=\"https://ml.azure.com/experiments/id/cb161e75-7639-4c84-a820-c784f7d50c20?wsid=/subscriptions/16bc73b5-82be-47f2-b5ab-f2373344794c/resourcegroups/epe-poc-nazeer/workspaces/nahmed30-azureml-workspace&amp;tid=db05faca-c82a-4b9d-b9c5-0f64b6755421\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 52,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661660535937
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create compute\n",
        "\n",
        "Hyperparameter tuning involves running multiple training iterations with different hyperparameter values and comparing the performance metrics of the resulting models. To do this efficiently, we'll take advantage of on-demand cloud compute and create a cluster - this will allow multiple training iterations to be run concurrently.\n",
        "\n",
        "Use the following code to specify an Azure Machine Learning compute cluster (it will be created if it doesn't already exist).\n",
        "\n",
        "> **Important**: Change *your-compute-cluster* to the name of your compute cluster in the code below before running it! Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# NOTE: update the cluster name to match the existing cluster\n",
        "# Choose a name for your CPU cluster\n",
        "amlcompute_cluster_name = \"cpu-cluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',# for GPU, use \"STANDARD_NC6\"\n",
        "                                                           #vm_priority = 'lowpriority', # optional\n",
        "                                                           max_nodes=4)\n",
        "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
        "\n",
        "compute_target.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)\n",
        "# For a more detailed view of current AmlCompute status, use get_status()."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\nSucceeded.....................................................................................................................\nAmlCompute wait for completion finished\n\nWait timeout has been reached\nCurrent provisioning state of AmlCompute is \"Succeeded\" and current node count is \"0\"\n"
        }
      ],
      "execution_count": 53,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1661661150577
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note**: Compute instances and clusters are based on standard Azure virtual machine images. For this exercise, the *Standard_DS11_v2* image is recommended to achieve the optimal balance of cost and performance. If your subscription has a quota that does not include this image, choose an alternative image; but bear in mind that a larger image may incur higher cost and a smaller image may not be sufficient to complete the tasks. Alternatively, ask your Azure administrator to extend your quota.\n",
        "\n",
        "You'll need a Python environment to be hosted on the compute, so let's define that as Conda configuration file."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $project_folder/hyperdrive_env.yml\n",
        "name: batch_environment\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- scikit-learn\n",
        "- pandas\n",
        "- numpy\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.take(5).to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661576036774
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661576054706
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "df.v1.value_counts().plot(kind=\"pie\",\n",
        "                                           fontsize=16,\n",
        "                                           labels=[\"Spam\", \"Ham\"],\n",
        "                                           ylabel=\"Spam vs Ham\",\n",
        "                                           autopct='%1.1f%%');\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(x=\"v1\",data=df, palette=\"pastel\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661576077792
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "ax1 = df.query(\"v1=='spam'\").v2.map(lambda x: len(x.split())).plot(kind=\"hist\",\n",
        "                                                                    color=\"cyan\",\n",
        "                                                                    title=\"Spam\",\n",
        "                                                                    edgecolor='white');\n",
        "plt.subplot(1, 2, 2)\n",
        "ax2 = df.query(\"v1=='ham'\").v2.map(lambda x: len(x.split())).plot(kind=\"hist\",\n",
        "                                                                    color=\"orange\",\n",
        "                                                                    title=\"Ham\",\n",
        "                                                                    edgecolor='white');\n",
        "\n",
        "ax1.grid(visible = True, color ='grey',linestyle ='-.', linewidth = 0.5,alpha = 0.6)\n",
        "ax2.grid(visible = True, color ='grey',linestyle ='-.', linewidth = 0.5,alpha = 0.6)\n",
        "plt.suptitle('Word distribution in SMS')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661576087627
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "stop_words= set(stopwords.words(\"english\"))\n",
        "\n",
        "stop_words.update(['https', 'http', 'amp', 'CO', 't', 'u', 'new', \"I'm\", \"would\"])\n",
        "\n",
        "wc = WordCloud(width=800,\n",
        "               height=400,\n",
        "               max_words=200,\n",
        "               stopwords=stop_words,\n",
        "               background_color='white',\n",
        "               max_font_size=150)\n",
        "spam = df.query(\"v1=='spam'\").v2.str.cat(sep=\" \")\n",
        "\n",
        "ham = df.query(\"v1=='ham'\").v2.str.cat(sep=\" \")\n",
        "\n",
        "print('\\n\\nWord Cloud for Spam messages\\n\\n')\n",
        "wc.generate(spam)\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print('\\n\\nWord Cloud for Ham messages\\n\\n')\n",
        "wc.generate(ham)\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661576111007
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.replace('spam', 1)\n",
        "df = df.replace('ham', 0)\n",
        "df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661576129795
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanText(text):\n",
        "    whitespace = re.compile(r\"\\s+\")\n",
        "    web_address = re.compile(r\"(?i)http(s):\\/\\/[a-z0-9.~_\\-\\/]+\")\n",
        "    user = re.compile(r\"(?i)@[a-z0-9_]+\")\n",
        "    text = text.replace('.', '')\n",
        "    text = whitespace.sub(' ', text)\n",
        "    text = web_address.sub('', text)\n",
        "    text = user.sub('', text)\n",
        "    text = re.sub(r\"\\[[^()]*\\]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = re.sub(r'[^\\w\\s]','',text)\n",
        "    text = re.sub(r\"(?:@\\S*|#\\S*|http(?=.*://)\\S*)\", \"\", text)\n",
        "    return text.lower()\n",
        "\n",
        "df.v2 = [cleanText(item) for item in df.v2]\n",
        "df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661576139610
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.oov_token = '<oovToken>'\n",
        "tokenizer.fit_on_texts(df.v2)\n",
        "vocab = tokenizer.word_index\n",
        "vocabCount = len(vocab)+1\n",
        "\n",
        "vocabCount"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661576155989
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SPLIT = 5000\n",
        "\n",
        "xTrain = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(df.v2.to_numpy()), padding='pre', maxlen=171)\n",
        "yTrain = df.v1.to_numpy()\n",
        "dim = xTrain.shape[1]\n",
        "xTest = xTrain[SPLIT:]\n",
        "yTest = yTrain[SPLIT:]\n",
        "\n",
        "xTrain = xTrain[:SPLIT]\n",
        "yTrain = yTrain[:SPLIT]\n",
        "\n",
        "xTrain.shape, yTrain.shape, xTest.shape, yTest.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661576183567
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building and Fitting the models**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(input_dim=vocabCount+1, output_dim=64, input_length=dim))\n",
        "model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661576219392
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(xTrain, yTrain, epochs=10, shuffle=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661576245654
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(xTest, yTest)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661576261937
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Congratulations, you have won a 10000 dollars lottery. Please give your bank details to claim the money\"\n",
        "processedText = cleanText(text)\n",
        "#print(processedText)\n",
        "finalText = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([processedText]), padding='pre', maxlen=171)\n",
        "prediction = model.predict(finalText)\n",
        "print(\"prediction shape\", prediction.shape)\n",
        "print(prediction)\n",
        "\n",
        "print(np.int(np.rint(prediction[0,0])))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661576291249
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I'll meet you at nariman point tomorrow\"\n",
        "processedText = cleanText(text)\n",
        "#print(processedText)\n",
        "finalText = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([processedText]), padding='pre', maxlen=171)\n",
        "prediction = model.predict(finalText)\n",
        "print(\"prediction shape\", prediction.shape)\n",
        "print(prediction)\n",
        "print(np.int(np.rint(prediction[0,0])))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661576301038
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"You won $100 click link below to collect\"\n",
        "processedText = cleanText(text)\n",
        "#print(processedText)\n",
        "finalText = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([processedText]), padding='pre', maxlen=171)\n",
        "prediction = model.predict(finalText)\n",
        "print(\"prediction shape\", prediction.shape)\n",
        "print(prediction)\n",
        "print(np.int(np.rint(prediction[0,0])))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661576315739
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run a hyperparameter tuning experiment\n",
        "\n",
        "Azure Machine Learning includes a hyperparameter tuning capability through *hyperdrive* experiments. These experiments launch multiple child runs, each with a different hyperparameter combination. The run producing the best model (as determined by the logged target performance metric for which you want to optimize) can be identified, and its trained model selected for registration and deployment.\n",
        "\n",
        "> **Note**: In this example, we aren't specifying an early stopping policy. Such a policy is only relevant if the training script performs multiple training iterations, logging the primary metric for each iteration. This approach is typically employed when training deep neural network models over multiple *epochs*."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/tutorials/keras/keras_tuner"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661576615677
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model (hp):\n",
        "    hpmodel = tf.keras.Sequential()\n",
        "    hpmodel.add(tf.keras.layers.Embedding(input_dim=vocabCount+1, output_dim=64, input_length=dim))\n",
        "    hpmodel.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "    for i in range(hp.Int('num_layers', 2, 20)):\n",
        "        hpmodel.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
        "                                                min_value=32,\n",
        "                                                max_value=512,\n",
        "                                                step=32),\n",
        "                                 activation='relu'))\n",
        "    hpmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))    \n",
        "    hpmodel.compile(loss='binary_crossentropy', \n",
        "                    optimizer=tf.keras.optimizers.Adam(\n",
        "                        hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])), \n",
        "                    metrics=['accuracy'])\n",
        "    return hpmodel\n",
        "\n",
        "## ------------------------------------------\n",
        "\n",
        "#model = tf.keras.Sequential()\n",
        "#model.add(tf.keras.layers.Embedding(input_dim=vocabCount+1, output_dim=64, input_length=dim))\n",
        "#model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "#model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "#model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 55,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661663103618
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def model_builder(hp):\n",
        "  modelhp = tf.keras.Sequential()\n",
        "\n",
        "  modelhp.add(tf.keras.layers.Embedding(input_dim=vocabCount+1, output_dim=64, input_length=dim))\n",
        "  modelhp.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "  modelhp.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "  modelhp.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "  modelhp.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  modelhp.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  # modelhp.add(tf.keras.layers.Flatten(input_shape=(32, 171)))\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  modelhp.add(tf.keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "  modelhp.add(tf.keras.layers.Dense(10))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  modelhp.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return modelhp"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='spam_training-hyperdrive',\n",
        "                     project_name='hyperparameter_kt')"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='spam_training-hyperdrive',\n",
        "    project_name='hyperparameter_kt'\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "INFO:tensorflow:Reloading Oracle from existing project spam_training-hyperdrive/hyperparameter_kt/oracle.json\nINFO:tensorflow:Reloading Tuner from spam_training-hyperdrive/hyperparameter_kt/tuner0.json\n"
        }
      ],
      "execution_count": 56,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661663470338
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Search space summary\nDefault search space size: 2\nunits (Int)\n{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\nlearning_rate (Choice)\n{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
        }
      ],
      "execution_count": 57,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661663550914
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "outputs": [],
      "execution_count": 64,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661664221063
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(xTrain, yTrain, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "INFO:tensorflow:Oracle triggered exit\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 67,
          "data": {
            "text/plain": "<bound method HyperParameters.get_config of <keras_tuner.engine.hyperparameters.HyperParameters object at 0x7fe333f91220>>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 67,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661664297117
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nThe hyperparameter search is complete. The optimal number of units in the first densely-connected\nlayer is 480 and the optimal learning rate for the optimizer\nis 0.01.\n\n"
        }
      ],
      "execution_count": 68,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661664326965
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "modelhp = tuner.hypermodel.build(best_hps)\n",
        "history = modelhp.fit(xTrain, yTrain, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.9075 - val_loss: 0.1328 - val_accuracy: 0.9590\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/50\n125/125 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9835 - val_loss: 0.0563 - val_accuracy: 0.9830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/50\n125/125 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 0.9915 - val_loss: 0.0650 - val_accuracy: 0.9830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/50\n125/125 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 0.0705 - val_accuracy: 0.9850\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/50\n125/125 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.1019 - val_accuracy: 0.9830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9960 - val_loss: 0.0686 - val_accuracy: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/50\n125/125 [==============================] - 1s 4ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0941 - val_accuracy: 0.9730\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.1415 - val_accuracy: 0.9780\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/50\n125/125 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.0844 - val_accuracy: 0.9850\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9955 - val_loss: 0.1039 - val_accuracy: 0.9830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0863 - val_accuracy: 0.9800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 0.0892 - val_accuracy: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0861 - val_accuracy: 0.9800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.1153 - val_accuracy: 0.9840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9977 - val_loss: 0.1181 - val_accuracy: 0.9660\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.1106 - val_accuracy: 0.9830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1689 - val_accuracy: 0.9760\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.1290 - val_accuracy: 0.9810\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1142 - val_accuracy: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9983 - val_loss: 0.1094 - val_accuracy: 0.9780\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9983 - val_loss: 0.1567 - val_accuracy: 0.9810\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.1482 - val_accuracy: 0.9760\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0890 - val_accuracy: 0.9830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9977 - val_loss: 0.0955 - val_accuracy: 0.9840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0942 - val_accuracy: 0.9840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/50\n125/125 [==============================] - 0s 4ms/step - loss: 9.2789e-04 - accuracy: 0.9998 - val_loss: 0.1711 - val_accuracy: 0.9780\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/50\n125/125 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.1030 - val_accuracy: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/50\n125/125 [==============================] - 0s 4ms/step - loss: 6.3033e-05 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9850\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/50\n125/125 [==============================] - 0s 4ms/step - loss: 6.1018e-05 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9850\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30/50\n125/125 [==============================] - 0s 4ms/step - loss: 5.0423e-05 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31/50\n125/125 [==============================] - 0s 4ms/step - loss: 2.0025e-05 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32/50\n125/125 [==============================] - 0s 4ms/step - loss: 1.5883e-05 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33/50\n125/125 [==============================] - 0s 4ms/step - loss: 1.2225e-05 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34/50\n125/125 [==============================] - 0s 4ms/step - loss: 9.3358e-06 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35/50\n125/125 [==============================] - 0s 4ms/step - loss: 8.8467e-06 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36/50\n125/125 [==============================] - 1s 4ms/step - loss: 7.8623e-06 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37/50\n125/125 [==============================] - 0s 4ms/step - loss: 6.1734e-06 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 38/50\n125/125 [==============================] - 0s 4ms/step - loss: 7.9292e-06 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 0.9850\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 39/50\n125/125 [==============================] - 0s 4ms/step - loss: 5.4063e-06 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40/50\n125/125 [==============================] - 0s 4ms/step - loss: 4.4758e-06 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 41/50\n125/125 [==============================] - 0s 4ms/step - loss: 4.0406e-06 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 42/50\n125/125 [==============================] - 0s 4ms/step - loss: 3.4866e-06 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 43/50\n125/125 [==============================] - 0s 4ms/step - loss: 3.1753e-06 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 44/50\n125/125 [==============================] - 0s 4ms/step - loss: 3.0348e-06 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 45/50\n125/125 [==============================] - 0s 4ms/step - loss: 2.6893e-06 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 46/50\n125/125 [==============================] - 0s 4ms/step - loss: 2.6249e-06 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 47/50\n125/125 [==============================] - 0s 4ms/step - loss: 2.2098e-06 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 48/50\n125/125 [==============================] - 0s 4ms/step - loss: 1.9599e-06 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 49/50\n125/125 [==============================] - 0s 4ms/step - loss: 1.6539e-06 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 50/50\n125/125 [==============================] - 0s 4ms/step - loss: 1.7609e-06 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nBest epoch: 6\n"
        }
      ],
      "execution_count": 70,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661664563206
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(xTrain, yTrain, epochs=best_epoch, validation_split=0.2)\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = modelhp.evaluate(xTest, yTest)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "18/18 [==============================] - 0s 927us/step - loss: 0.1309 - accuracy: 0.9860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n[test loss, test accuracy]: [0.13093294203281403, 0.9860140085220337]\n"
        }
      ],
      "execution_count": 71,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661664593148
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"You won $100 click link below to collect\"\n",
        "processedText = cleanText(text)\n",
        "#print(processedText)\n",
        "finalText = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([processedText]), padding='pre', maxlen=171)\n",
        "prediction = modelhp.predict(finalText)\n",
        "print(\"prediction shape\", prediction.shape)\n",
        "print(prediction)\n",
        "print(prediction[0,0])\n",
        "print(np.int(np.rint(prediction[0,0])))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "prediction shape (1, 1)\n[[0.9999424]]\n0.9999424\n1\n"
        }
      ],
      "execution_count": 72,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661664624852
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.train.hyperdrive import GridParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Create a Python environment for the experiment\n",
        "hyper_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/hyperdrive_env.yml\")\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='diabetes_training.py',\n",
        "                                # Add non-hyperparameter arguments -in this case, the training dataset\n",
        "                                arguments = ['--input-data', diabetes_ds.as_named_input('training_data')],\n",
        "                                environment=hyper_env,\n",
        "                                compute_target = training_cluster)\n",
        "\n",
        "# Sample a range of parameter values\n",
        "params = GridParameterSampling(\n",
        "    {\n",
        "        # Hyperdrive will try 6 combinations, adding these as script arguments\n",
        "        '--learning_rate': choice(0.01, 0.1, 1.0),\n",
        "        '--n_estimators' : choice(10, 100)\n",
        "    }\n",
        ")\n",
        "\n",
        "# Configure hyperdrive settings\n",
        "hyperdrive = HyperDriveConfig(run_config=script_config, \n",
        "                          hyperparameter_sampling=params, \n",
        "                          policy=None, # No early stopping policy\n",
        "                          primary_metric_name='AUC', # Find the highest AUC metric\n",
        "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
        "                          max_total_runs=6, # Restict the experiment to 6 iterations\n",
        "                          max_concurrent_runs=2) # Run up to 2 iterations in parallel\n",
        "\n",
        "# Run the experiment\n",
        "experiment = Experiment(workspace=ws, name='mslearn-diabetes-hyperdrive')\n",
        "run = experiment.submit(config=hyperdrive)\n",
        "\n",
        "# Show the status in the notebook as the experiment runs\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1661449060106
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I'll meet you at nariman point tomorrow\"\n",
        "processedText = cleanText(text)\n",
        "#print(processedText)\n",
        "finalText = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([processedText]), padding='pre', maxlen=171)\n",
        "prediction = modelhp.predict(finalText)\n",
        "print(\"prediction shape\", prediction.shape)\n",
        "print(prediction)\n",
        "print(np.int(np.rint(prediction[0,0])))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "prediction shape (1, 1)\n[[1.3286123e-09]]\n0\n"
        }
      ],
      "execution_count": 73,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661664681655
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can view the experiment run status in the widget above. You can also view the main Hyperdrive experiment run and its child runs in [Azure Machine Learning studio](https://ml.azure.com).\n",
        "\n",
        "> **Note**: If a message indicating that a non-numeric can't be visualized is displayed, you can ignore it.\n",
        "\n",
        "## Determine the best performing run\n",
        "\n",
        "When all of the runs have finished, you can find the best one based on the performance metric you specified (in this case, the one with the best AUC)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all child runs, sorted by the primary metric\n",
        "for child_run in run.get_children_sorted_by_primary_metric():\n",
        "    print(child_run)\n",
        "\n",
        "# Get the best run, and its metrics and arguments\n",
        "best_run = run.get_best_run_by_primary_metric()\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "script_arguments = best_run.get_details() ['runDefinition']['arguments']\n",
        "print('Best Run Id: ', best_run.id)\n",
        "print(' -AUC:', best_run_metrics['AUC'])\n",
        "print(' -Accuracy:', best_run_metrics['Accuracy'])\n",
        "print(' -Arguments:',script_arguments)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1661452124140
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you've found the best run, you can register the model it trained."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "# Register model\n",
        "best_run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                        tags={'Training context':'Hyperdrive'},\n",
        "                        properties={'AUC': best_run_metrics['AUC'], 'Accuracy': best_run_metrics['Accuracy']})\n",
        "\n",
        "# List registered models\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1661452153039
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **More Information**: For more information about Hyperdrive, see the [Azure ML documentation](https://docs.microsoft.com/azure/machine-learning/how-to-tune-hyperparameters)."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}