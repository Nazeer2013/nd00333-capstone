{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tune Hyperparameters\n",
        "\n",
        "There are many machine learning algorithms that require *hyperparameters* (parameter values that influence training, but can't be determined from the training data itself). For example, when training a logistic regression model, you can use a *regularization rate* hyperparameter to counteract bias in the model; or when training a convolutional neural network, you can use hyperparameters like *learning rate* and *batch size* to control how weights are adjusted and how many data items are processed in a mini-batch respectively. The choice of hyperparameter values can significantly affect the performance of a trained model, or the time taken to train it; and often you need to try multiple combinations to find the optimal solution.\n",
        "\n",
        "In this case, you'll train a classification model with two hyperparameters, but the principles apply to any kind of model you can train with Azure Machine Learning."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "To get started, connect to your workspace.\n",
        "\n",
        "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import csv\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import pkg_resources\n",
        "\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import pydot\n",
        "import graphviz\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "\n",
        "# Check core SDK version number\n",
        "# print(\"SDK version:\", azureml.core.VERSION)\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))\n",
        "\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n",
        "\n",
        "print(\"Tensorflow version: \", tf.__version__)\n",
        "print(\"Current DateTime: \", datetime.now(pytz.timezone(\"America/New_York\")).strftime(\"%m/%d/%Y %H:%M:%S\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.41.0 to work with nahmed30-azureml-workspace\nnahmed30-azureml-workspace\nepe-poc-nazeer\ncentralus\n16bc73b5-82be-47f2-b5ab-f2373344794c\nTensorflow version:  2.2.0\nCurrent DateTime:  08/29/2022 22:18:00\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1661825882921
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras import models, layers\n",
        "from keras_tuner import HyperModel, RandomSearch, Hyperband, BayesianOptimization\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661825920725
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data\n",
        "\n",
        "In this lab, you'll use a dataset containing details of diabetes patients. Run the cell below to create this dataset (if it already exists, the existing version will be used)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "# Try to load the dataset from the Workspace. Otherwise, create it from the file\n",
        "# NOTE: update the key to match the dataset name\n",
        "found = False\n",
        "key = \"UdacityPrjEmailSpamDataSet\"\n",
        "description_text = \"Spam Detection DataSet for Udacity Capstone Proj \"\n",
        "\n",
        "dataset = None\n",
        "if key in ws.datasets.keys(): \n",
        "        found = True\n",
        "        dataset = ws.datasets[key] \n",
        "\n",
        "df = dataset.to_pandas_dataframe()\n",
        "df.describe()\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "          v1                      v2  \\\ncount   5572                    5572   \nunique     2                    5169   \ntop      ham  Sorry, I'll call later   \nfreq    4825                      30   \n\n                                                  Column3  \\\ncount                                                  50   \nunique                                                 43   \ntop      bt not his girlfrnd... G o o d n i g h t . . .@\"   \nfreq                                                    3   \n\n                      Column4  Column5  \ncount                      12        6  \nunique                     10        5  \ntop      MK17 92H. 450Ppw 16\"  GNT:-)\"  \nfreq                        2        2  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>Column3</th>\n      <th>Column4</th>\n      <th>Column5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5572</td>\n      <td>5572</td>\n      <td>50</td>\n      <td>12</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2</td>\n      <td>5169</td>\n      <td>43</td>\n      <td>10</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>ham</td>\n      <td>Sorry, I'll call later</td>\n      <td>bt not his girlfrnd... G o o d n i g h t . . .@\"</td>\n      <td>MK17 92H. 450Ppw 16\"</td>\n      <td>GNT:-)\"</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>4825</td>\n      <td>30</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661825942694
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare a training script\n",
        "\n",
        "Now let's create a folder for the training script you'll use to train the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a name for the run history container in the workspace.\n",
        "# NOTE: update these to match your existing experiment name\n",
        "experiment_folder = 'spam_training-hyperdrive'\n",
        "experiment_name = 'ml-spam-experiment-prjassign1'\n",
        "project_folder = 'spam_training-hyperdrive'\n",
        "\n",
        "os.makedirs(project_folder, exist_ok=True)\n",
        "\n",
        "print('Project Folder is ready.')\n",
        "\n",
        "experiment = Experiment(ws, experiment_name)\n",
        "experiment"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Project Folder is ready.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "Experiment(Name: ml-spam-experiment-prjassign1,\nWorkspace: nahmed30-azureml-workspace)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>ml-spam-experiment-prjassign1</td><td>nahmed30-azureml-workspace</td><td><a href=\"https://ml.azure.com/experiments/id/cb161e75-7639-4c84-a820-c784f7d50c20?wsid=/subscriptions/16bc73b5-82be-47f2-b5ab-f2373344794c/resourcegroups/epe-poc-nazeer/workspaces/nahmed30-azureml-workspace&amp;tid=db05faca-c82a-4b9d-b9c5-0f64b6755421\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661826097708
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create compute\n",
        "\n",
        "Hyperparameter tuning involves running multiple training iterations with different hyperparameter values and comparing the performance metrics of the resulting models. To do this efficiently, we'll take advantage of on-demand cloud compute and create a cluster - this will allow multiple training iterations to be run concurrently.\n",
        "\n",
        "Use the following code to specify an Azure Machine Learning compute cluster (it will be created if it doesn't already exist).\n",
        "\n",
        "> **Important**: Change *your-compute-cluster* to the name of your compute cluster in the code below before running it! Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# NOTE: update the cluster name to match the existing cluster\n",
        "# Choose a name for your CPU cluster\n",
        "amlcompute_cluster_name = \"cpu-cluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',# for GPU, use \"STANDARD_NC6\"\n",
        "                                                           #vm_priority = 'lowpriority', # optional\n",
        "                                                           max_nodes=4)\n",
        "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
        "\n",
        "compute_target.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)\n",
        "# For a more detailed view of current AmlCompute status, use get_status()."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\nSucceeded.....................................................................................................................\nAmlCompute wait for completion finished\n\nWait timeout has been reached\nCurrent provisioning state of AmlCompute is \"Succeeded\" and current node count is \"0\"\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1661826724026
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note**: Compute instances and clusters are based on standard Azure virtual machine images. For this exercise, the *Standard_DS11_v2* image is recommended to achieve the optimal balance of cost and performance. If your subscription has a quota that does not include this image, choose an alternative image; but bear in mind that a larger image may incur higher cost and a smaller image may not be sufficient to complete the tasks. Alternatively, ask your Azure administrator to extend your quota.\n",
        "\n",
        "You'll need a Python environment to be hosted on the compute, so let's define that as Conda configuration file."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $project_folder/hyperdrive_env.yml\n",
        "name: batch_environment\n",
        "dependencies:\n",
        "- python\n",
        "- scikit-learn\n",
        "- pandas\n",
        "- numpy\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting spam_training-hyperdrive/hyperdrive_env.yml\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.take(5).to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823033292
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661796271015
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "df.v1.value_counts().plot(kind=\"pie\",\n",
        "                                           fontsize=16,\n",
        "                                           labels=[\"Spam\", \"Ham\"],\n",
        "                                           ylabel=\"Spam vs Ham\",\n",
        "                                           autopct='%1.1f%%');\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(x=\"v1\",data=df, palette=\"pastel\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823120542
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "ax1 = df.query(\"v1=='spam'\").v2.map(lambda x: len(x.split())).plot(kind=\"hist\",\n",
        "                                                                    color=\"cyan\",\n",
        "                                                                    title=\"Spam\",\n",
        "                                                                    edgecolor='white');\n",
        "plt.subplot(1, 2, 2)\n",
        "ax2 = df.query(\"v1=='ham'\").v2.map(lambda x: len(x.split())).plot(kind=\"hist\",\n",
        "                                                                    color=\"orange\",\n",
        "                                                                    title=\"Ham\",\n",
        "                                                                    edgecolor='white');\n",
        "\n",
        "ax1.grid(visible = True, color ='grey',linestyle ='-.', linewidth = 0.5,alpha = 0.6)\n",
        "ax2.grid(visible = True, color ='grey',linestyle ='-.', linewidth = 0.5,alpha = 0.6)\n",
        "plt.suptitle('Word distribution in SMS')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823134224
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "stop_words= set(stopwords.words(\"english\"))\n",
        "\n",
        "stop_words.update(['https', 'http', 'amp', 'CO', 't', 'u', 'new', \"I'm\", \"would\"])\n",
        "\n",
        "wc = WordCloud(width=800,\n",
        "               height=400,\n",
        "               max_words=200,\n",
        "               stopwords=stop_words,\n",
        "               background_color='white',\n",
        "               max_font_size=150)\n",
        "spam = df.query(\"v1=='spam'\").v2.str.cat(sep=\" \")\n",
        "\n",
        "ham = df.query(\"v1=='ham'\").v2.str.cat(sep=\" \")\n",
        "\n",
        "print('\\n\\nWord Cloud for Spam messages\\n\\n')\n",
        "wc.generate(spam)\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print('\\n\\nWord Cloud for Ham messages\\n\\n')\n",
        "wc.generate(ham)\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823196604
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.replace('spam', 1)\n",
        "df = df.replace('ham', 0)\n",
        "df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823209356
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanText(text):\n",
        "    whitespace = re.compile(r\"\\s+\")\n",
        "    web_address = re.compile(r\"(?i)http(s):\\/\\/[a-z0-9.~_\\-\\/]+\")\n",
        "    user = re.compile(r\"(?i)@[a-z0-9_]+\")\n",
        "    text = text.replace('.', '')\n",
        "    text = whitespace.sub(' ', text)\n",
        "    text = web_address.sub('', text)\n",
        "    text = user.sub('', text)\n",
        "    text = re.sub(r\"\\[[^()]*\\]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = re.sub(r'[^\\w\\s]','',text)\n",
        "    text = re.sub(r\"(?:@\\S*|#\\S*|http(?=.*://)\\S*)\", \"\", text)\n",
        "    return text.lower()\n",
        "\n",
        "df.v2 = [cleanText(item) for item in df.v2]\n",
        "df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823256005
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.oov_token = '<oovToken>'\n",
        "tokenizer.fit_on_texts(df.v2)\n",
        "vocab = tokenizer.word_index\n",
        "vocabCount = len(vocab)+1\n",
        "\n",
        "vocabCount"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823269629
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SPLIT = 5000\n",
        "\n",
        "xTrain = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(df.v2.to_numpy()), padding='pre', maxlen=171)\n",
        "yTrain = df.v1.to_numpy()\n",
        "dim = xTrain.shape[1]\n",
        "xTest = xTrain[SPLIT:]\n",
        "yTest = yTrain[SPLIT:]\n",
        "\n",
        "xTrain = xTrain[:SPLIT]\n",
        "yTrain = yTrain[:SPLIT]\n",
        "\n",
        "xTrain.shape, yTrain.shape, xTest.shape, yTest.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823306481
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AzureML Hyperdrive Hyperparameters Initialization**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import choice, uniform\n",
        "from azureml.core import Environment, ScriptRunConfig\n",
        "import os\n",
        "\n",
        "# Specify parameter sampler\n",
        "# https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.randomparametersampling?view=azure-ml-py\n",
        "\n",
        "# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/ml-frameworks/scikit-learn/train-hyperparameter-tune-deploy-with-sklearn/train-hyperparameter-tune-deploy-with-sklearn.ipynb\n",
        "\n",
        "ps = RandomParameterSampling( {\n",
        "    \"--units_l1\": uniform('units', min_value=8,max_value=128),\n",
        "    \"--optim\": choice('optimizer', values = ['adam', 'sgd', 'rmsprop', 'adadelta']) \n",
        "    }\n",
        ")\n",
        "\n",
        "# units_l1=hp.Int('units', min_value=8,max_value=128, step=8)\n",
        "# optim=hp.Choice('optimizer', values = ['adam', 'sgd', 'rmsprop', 'adadelta'])\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661856194360
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Straight to hyperparameter tuning **"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(input_dim=vocabCount+1, output_dim=64, input_length=dim))\n",
        "model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823323807
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the Hypermodel**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_myhm(hp):\r\n",
        "    model = tf.keras.Sequential()\r\n",
        "    model.add(tf.keras.layers.Embedding(input_dim=vocabCount+1, output_dim=64, input_length=dim))\r\n",
        "    model.add(tf.keras.layers.GlobalAveragePooling1D())\r\n",
        "    units_l1=hp.Int('units', min_value=8,max_value=128, step=8)\r\n",
        "    model.add(tf.keras.layers.Dense(units=units_l1, activation='relu', input_dim=8))\r\n",
        "    model.add(tf.keras.layers.Dense(32, activation='relu'))\r\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "    optim=hp.Choice('optimizer', values = ['adam', 'sgd', 'rmsprop', 'adadelta'])\r\n",
        "\r\n",
        "    model.compile( optim, loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "    model.summary()\r\n",
        "\r\n",
        "    return model\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823422766
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_tuner import RandomSearch\n",
        "from keras_tuner import Objective\n",
        "\n",
        "tuner =  RandomSearch(build_myhm,\n",
        "                      objective='val_accuracy',\n",
        "                      max_trials=5,\n",
        "                      project_name='spam_randomsearch',\n",
        "                      directory='spam_randomsearch_dir',\n",
        "                      overwrite=True\n",
        "                    )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823448016
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# xTrain.shape, yTrain.shape, xTest.shape, yTest.shape\n",
        "tuner.search(xTrain, yTrain, batch_size=32, epochs=10, validation_data=(xTest, yTest))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823528006
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.get_best_hyperparameters()[0].values"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823559062
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model=tuner.get_best_models(num_models=1)[0]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823574713
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.summary()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823679177
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.fit(xTrain, yTrain, batch_size=32, epochs=100, initial_epoch=6, validation_data=(xTest, yTest))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823756417
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.summary()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661809666878
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.evaluate(xTest, yTest)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823854919
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Congratulations, you have won a 10000 dollars lottery. Please give your bank details to claim the money\"\n",
        "processedText = cleanText(text)\n",
        "#print(processedText)\n",
        "finalText = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([processedText]), padding='pre', maxlen=171)\n",
        "prediction = best_model.predict(finalText)\n",
        "print(\"prediction shape\", prediction.shape)\n",
        "print(prediction)\n",
        "\n",
        "print(np.int(np.rint(prediction[0,0])))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823868419
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I'll meet you at nariman point tomorrow\"\n",
        "processedText = cleanText(text)\n",
        "#print(processedText)\n",
        "finalText = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([processedText]), padding='pre', maxlen=171)\n",
        "prediction = best_model.predict(finalText)\n",
        "print(\"prediction shape\", prediction.shape)\n",
        "print(prediction)\n",
        "print(np.int(np.rint(prediction[0,0])))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661823978938
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"You won $100 click link below to collect\"\n",
        "processedText = cleanText(text)\n",
        "#print(processedText)\n",
        "finalText = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([processedText]), padding='pre', maxlen=171)\n",
        "prediction = best_model.predict(finalText)\n",
        "print(\"prediction shape\", prediction.shape)\n",
        "print(prediction)\n",
        "print(np.int(np.rint(prediction[0,0])))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661824011873
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run a hyperparameter tuning experiment\n",
        "\n",
        "Azure Machine Learning includes a hyperparameter tuning capability through *hyperdrive* experiments. These experiments launch multiple child runs, each with a different hyperparameter combination. The run producing the best model (as determined by the logged target performance metric for which you want to optimize) can be identified, and its trained model selected for registration and deployment.\n",
        "\n",
        "> **Note**: In this example, we aren't specifying an early stopping policy. Such a policy is only relevant if the training script performs multiple training iterations, logging the primary metric for each iteration. This approach is typically employed when training deep neural network models over multiple *epochs*."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/tutorials/keras/keras_tuner"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661666219386
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661824106796
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(xTrain, yTrain, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661824246355
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661824341303
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "modelhp = tuner.hypermodel.build(best_hps)\n",
        "history = modelhp.fit(xTrain, yTrain, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661824423279
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = modelhp.evaluate(xTest, yTest)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661824568541
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"You won $100 click link below to collect\"\n",
        "processedText = cleanText(text)\n",
        "#print(processedText)\n",
        "finalText = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([processedText]), padding='pre', maxlen=171)\n",
        "prediction = modelhp.predict(finalText)\n",
        "print(\"prediction shape\", prediction.shape)\n",
        "print(prediction)\n",
        "print(prediction[0,0])\n",
        "print(np.int(np.rint(prediction[0,0])))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661824642213
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I'll meet you at nariman point tomorrow\"\n",
        "processedText = cleanText(text)\n",
        "#print(processedText)\n",
        "finalText = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([processedText]), padding='pre', maxlen=171)\n",
        "prediction = modelhp.predict(finalText)\n",
        "print(\"prediction shape\", prediction.shape)\n",
        "print(prediction)\n",
        "print(np.int(np.rint(prediction[0,0])))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1661824657718
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you've found the best run, you can register the model it trained."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **More Information**: For more information about Hyperdrive, see the [Azure ML documentation](https://docs.microsoft.com/azure/machine-learning/how-to-tune-hyperparameters)."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}