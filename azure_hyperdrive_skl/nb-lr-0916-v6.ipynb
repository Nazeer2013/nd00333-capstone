{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The \"Azure ML SDK\" for SMS Spam Inference \n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, we will show the use of Azure ML SDK to train, deploy and consume a model through Azure ML.\n",
        "\n",
        "\n",
        "Steps:\n",
        "\n",
        "1. Create a workspace. Create an Experiment in an existing Workspace.\n",
        "2. Create a Compute cluster.\n",
        "3. Load the dataset.\n",
        "4. Configure AutoML using AutoMLConfig.\n",
        "5. Run the AutoML experiment.\n",
        "6. Explore the results and get the best model.\n",
        "7. Register the best model.\n",
        "8. Deploy the best model.\n",
        "9. Consume the endpoint.\n",
        "\n",
        "## Azure Machine Learning SDK-specific imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1663299317506
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.core.model import InferenceConfig, Model\n",
        "from azureml.core.webservice import AciWebservice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Workspace\n",
        "Initialize a workspace object from persisted configuration. Make sure the config file is present at .\\config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1663299318085
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nahmed30-azureml-workspace\n",
            "epe-poc-nazeer\n",
            "centralus\n",
            "16bc73b5-82be-47f2-b5ab-f2373344794c\n"
          ]
        }
      ],
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create an Azure ML experiment\n",
        "\n",
        "Let's create an experiment named 'aml-experiment' in the workspace we just initialized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1663299318382
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>nb_lr_exp_0916_v6</td><td>nahmed30-azureml-workspace</td><td><a href=\"https://ml.azure.com/experiments/id/9c496b20-1f94-4d02-9c87-e8cc50a7e159?wsid=/subscriptions/16bc73b5-82be-47f2-b5ab-f2373344794c/resourcegroups/epe-poc-nazeer/workspaces/nahmed30-azureml-workspace&amp;tid=db05faca-c82a-4b9d-b9c5-0f64b6755421\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Experiment(Name: nb_lr_exp_0916_v6,\n",
              "Workspace: nahmed30-azureml-workspace)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "experiment_name = 'nb_lr_exp_0916_v6'\n",
        "experiment = Experiment(ws, experiment_name)\n",
        "experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Compute Cluster\n",
        "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/concept-azure-machine-learning-architecture#compute-target) for your AutoML run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1663299318683
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing AML compute context.\n"
          ]
        }
      ],
      "source": [
        "aml_name = \"cpu-cluster\"\n",
        "try:\n",
        "    aml_compute = AmlCompute(ws, aml_name)\n",
        "    print('Found existing AML compute context.')\n",
        "except:\n",
        "    print('Creating new AML compute context.')\n",
        "    aml_config = AmlCompute.provisioning_configuration(vm_size = \"Standard_D2_v2\", min_nodes=1, max_nodes=3)\n",
        "    aml_compute = AmlCompute.create(ws, name = aml_name, provisioning_configuration = aml_config)\n",
        "    aml_compute.wait_for_completion(show_output = True)\n",
        "\n",
        "cts = ws.compute_targets\n",
        "compute_target = cts[aml_name]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data\n",
        "Make sure you have uploaded the dataset to Azure ML and that the key is the same name as the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1663299321736
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Column3</th>\n",
              "      <th>Column4</th>\n",
              "      <th>Column5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5572</td>\n",
              "      <td>5572</td>\n",
              "      <td>50</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2</td>\n",
              "      <td>5169</td>\n",
              "      <td>43</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>ham</td>\n",
              "      <td>Sorry, I'll call later</td>\n",
              "      <td>bt not his girlfrnd... G o o d n i g h t . . .@\"</td>\n",
              "      <td>MK17 92H. 450Ppw 16\"</td>\n",
              "      <td>GNT:-)\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>4825</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          v1                      v2  \\\n",
              "count   5572                    5572   \n",
              "unique     2                    5169   \n",
              "top      ham  Sorry, I'll call later   \n",
              "freq    4825                      30   \n",
              "\n",
              "                                                  Column3  \\\n",
              "count                                                  50   \n",
              "unique                                                 43   \n",
              "top      bt not his girlfrnd... G o o d n i g h t . . .@\"   \n",
              "freq                                                    3   \n",
              "\n",
              "                      Column4  Column5  \n",
              "count                      12        6  \n",
              "unique                     10        5  \n",
              "top      MK17 92H. 450Ppw 16\"  GNT:-)\"  \n",
              "freq                        2        2  "
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "key = 'UdacityPrjEmailSpamDataSet'\n",
        "smsspam_ds = ws.datasets[key]\n",
        "df = smsspam_ds.to_pandas_dataframe()\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Column3</th>\n",
              "      <th>Column4</th>\n",
              "      <th>Column5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1                                                 v2 Column3 Column4  \\\n",
              "0   ham  Go until jurong point, crazy.. Available only ...    None    None   \n",
              "1   ham                      Ok lar... Joking wif u oni...    None    None   \n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...    None    None   \n",
              "3   ham  U dun say so early hor... U c already then say...    None    None   \n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...    None    None   \n",
              "\n",
              "  Column5  \n",
              "0    None  \n",
              "1    None  \n",
              "2    None  \n",
              "3    None  \n",
              "4    None  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create workspace folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "experiment_folder = 'nb_lr_exp_0916_v6'\n",
        "os.makedirs(experiment_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting nb_lr_exp_0916_v6/hyperdrive_env.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile $experiment_folder/hyperdrive_env.yml\n",
        "name: batch_environment\n",
        "dependencies:\n",
        "- python=3.8.5\n",
        "- scikit-learn\n",
        "- pandas\n",
        "- numpy\n",
        "- regex\n",
        "- nltk\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create  Python script to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting nb_lr_exp_0916_v6/train.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $experiment_folder/train.py\n",
        "\n",
        "# Import libraries\n",
        "import argparse, joblib, os\n",
        "from azureml.core import Run\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import csv\n",
        "import string\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import regex as re\n",
        "\n",
        "import pickle\n",
        "import tempfile\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# Get script arguments\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "# Input dataset\n",
        "parser.add_argument(\"--input-data\", type=str, dest='input_data', help='training dataset')\n",
        "\n",
        "# Hyperparameters\n",
        "#parser.add_argument('--learning_rate', type=float, dest='learning_rate', default=0.1, help='learning rate')\n",
        "# parser.add_argument('--n_estimators', type=int, dest='n_estimators', default=100, help='number of estimators')\n",
        "\n",
        "parser.add_argument('--C', type=float, default=1.0, help=\"indicates regularization\")\n",
        "parser.add_argument('--max_iter', type=int, default=100, help=\"Maximum number of iterations\")\n",
        "\n",
        "# Add arguments to args collection\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Log Hyperparameter values\n",
        "# run.log('learning_rate',  np.float(args.learning_rate))\n",
        "# run.log('n_estimators',  np.int(args.n_estimators))\n",
        "\n",
        "run.log(\"Regularization Strength:\", np.float(args.C))\n",
        "run.log(\"Max iterations:\", np.int(args.max_iter))\n",
        "\n",
        " \n",
        "# load the sms spam dataset -- Get the training data from the input\n",
        "print(\"Loading SMS Spam Data...\")\n",
        "df = run.input_datasets['training_data'].to_pandas_dataframe() \n",
        "\n",
        "#--------------------------Prepare Data-------------------------------------------------\n",
        "# Cleanup and Prepare Data # Find and eliminate stop words \n",
        "nltk.download('stopwords')\n",
        "stop_words= set(stopwords.words(\"english\"))\n",
        "stop_words.update(['https', 'http', 'amp', 'CO', 't', 'u', 'new', \"I'm\", \"would\"])\n",
        "\n",
        "\n",
        "spam = df.query(\"v1=='spam'\").v2.str.cat(sep=\" \")\n",
        "ham = df.query(\"v1=='ham'\").v2.str.cat(sep=\" \")\n",
        "\n",
        "# convert spam to 1 and ham to 0\n",
        "df = df.replace('spam', 1)\n",
        "df = df.replace('ham', 0)\n",
        "\n",
        "# Clean the text\n",
        "def clean_text(text):\n",
        "    whitespace = re.compile(r\"\\s+\")\n",
        "    web_address = re.compile(r\"(?i)http(s):\\/\\/[a-z0-9.~_\\-\\/]+\")\n",
        "    user = re.compile(r\"(?i)@[a-z0-9_]+\")\n",
        "    text = text.replace('.', '')\n",
        "    text = whitespace.sub(' ', text)\n",
        "    text = web_address.sub('', text)\n",
        "    text = user.sub('', text)\n",
        "    text = re.sub(r\"\\[[^()]*\\]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = re.sub(r'[^\\w\\s]','',text)\n",
        "    text = re.sub(r\"(?:@\\S*|#\\S*|http(?=.*://)\\S*)\", \"\", text)\n",
        "    return text.lower()\n",
        "\n",
        "df.v2 = [clean_text(item) for item in df.v2]\n",
        "\n",
        "#---------------------More Data Prep-----------#\n",
        "df = df.drop(['Column3', 'Column4', 'Column5'], axis = 1)\n",
        "\n",
        "df_msg_copy = df['v2'].copy()\n",
        "\n",
        "# vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "def text_preprocess(text):\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
        "    return \" \".join(text)\n",
        "\n",
        "df_msg_copy = df_msg_copy.apply(text_preprocess)\n",
        "\n",
        "# text2 = vectorizer.fit_transform(df_msg_copy)\n",
        "\n",
        "def stemmer (text):\n",
        "    text = text.split()\n",
        "    words = \"\"\n",
        "    for i in text:\n",
        "            stemmer = SnowballStemmer(\"english\")\n",
        "            words += (stemmer.stem(i))+\" \"\n",
        "    return words\n",
        "\n",
        "df_msg_copy = df_msg_copy.apply(stemmer)\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "msg_mat = vectorizer.fit_transform(df_msg_copy)\n",
        "\n",
        "\n",
        "# Split Train and Test\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(msg_mat, df.v1, test_size=0.3, random_state=20)\n",
        "\n",
        "\n",
        "# --------------------------End Prepare Data--------------------------------------------\n",
        "# --------------------------Start Training----------------------------------------------\n",
        "# Train a Logistic Regression classification model without the specified hyperparameters\n",
        "print('Training a classification model')\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', penalty='l1', C=args.C, max_iter=args.max_iter )\n",
        "model.fit(xTrain, yTrain)\n",
        "pred = model.predict(xTest)\n",
        "acc = accuracy_score(yTest,pred)\n",
        "\n",
        "# ---------------------------End Training------------------------------------------------\n",
        "\n",
        "\n",
        "# Train a LogisticRegression classification model with the specified hyperparameters\n",
        "# print('Training a classification model')\n",
        "# model = LogisticRegression(learning_rate=args.learning_rate,\n",
        "#                                   n_estimators=args.n_estimators).fit(xTrain, yTrain)\n",
        "\n",
        "# calculate accuracy\n",
        "# y_hat = model.predict(xTest)\n",
        "# acc = np.average(y_hat == yTest)\n",
        "# print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(xTest)\n",
        "auc = roc_auc_score(yTest,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "\n",
        "\n",
        "# Save the model in the run outputs\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "joblib.dump(value=model, filename='outputs/model_v7.pkl')\n",
        "\n",
        "\n",
        "run.complete()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## HyperDrive Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#primary-metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run a hyperparameter tuning experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'runId': 'HD_d62506a6-83b4-428d-9a1c-9f66759854a7',\n",
              " 'target': 'cpu-cluster',\n",
              " 'status': 'Completed',\n",
              " 'startTimeUtc': '2022-09-18T14:25:01.168946Z',\n",
              " 'endTimeUtc': '2022-09-18T14:32:04.908121Z',\n",
              " 'services': {},\n",
              " 'properties': {'primary_metric_config': '{\"name\":\"Accuracy\",\"goal\":\"maximize\"}',\n",
              "  'resume_from': 'null',\n",
              "  'runTemplate': 'HyperDrive',\n",
              "  'azureml.runsource': 'hyperdrive',\n",
              "  'platform': 'AML',\n",
              "  'ContentSnapshotId': '596f8c31-04d6-46f0-ba36-973f47658aa9',\n",
              "  'user_agent': 'python/3.8.12 (macOS-10.15.7-x86_64-i386-64bit) msrest/0.6.21 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.44.0',\n",
              "  'space_size': '6',\n",
              "  'score': '0.9503588516746412',\n",
              "  'best_child_run_id': 'HD_d62506a6-83b4-428d-9a1c-9f66759854a7_4',\n",
              "  'best_metric_status': 'Succeeded',\n",
              "  'best_data_container_id': 'dcid.HD_d62506a6-83b4-428d-9a1c-9f66759854a7_4'},\n",
              " 'inputDatasets': [],\n",
              " 'outputDatasets': [],\n",
              " 'runDefinition': {'configuration': None,\n",
              "  'attribution': None,\n",
              "  'telemetryValues': {'amlClientType': 'azureml-sdk-train',\n",
              "   'amlClientModule': '[Scrubbed]',\n",
              "   'amlClientFunction': '[Scrubbed]',\n",
              "   'tenantId': 'db05faca-c82a-4b9d-b9c5-0f64b6755421',\n",
              "   'amlClientRequestId': 'ea42825a-a776-4e72-9850-3af010b3d1be',\n",
              "   'amlClientSessionId': 'bad93c46-9551-40df-b2d0-da8eb3d230ee',\n",
              "   'subscriptionId': '16bc73b5-82be-47f2-b5ab-f2373344794c',\n",
              "   'estimator': 'NoneType',\n",
              "   'samplingMethod': 'GRID',\n",
              "   'terminationPolicy': 'Default',\n",
              "   'primaryMetricGoal': 'maximize',\n",
              "   'maxTotalRuns': 36,\n",
              "   'maxConcurrentRuns': 2,\n",
              "   'maxDurationMinutes': 10080,\n",
              "   'vmSize': None},\n",
              "  'snapshotId': '596f8c31-04d6-46f0-ba36-973f47658aa9',\n",
              "  'snapshots': [],\n",
              "  'sourceCodeDataReference': None,\n",
              "  'parentRunId': None,\n",
              "  'dataContainerId': None,\n",
              "  'runType': None,\n",
              "  'displayName': None,\n",
              "  'environmentAssetId': None,\n",
              "  'properties': {},\n",
              "  'tags': {},\n",
              "  'aggregatedArtifactPath': None},\n",
              " 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://nahmed30storage.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_d62506a6-83b4-428d-9a1c-9f66759854a7/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=urp%2B0Gqc7rHSPlaVwOsCZ2QWGQQ3SiSeYSkIaWCCnhA%3D&skoid=990e57a2-6b09-4324-b33f-71ef714de994&sktid=db05faca-c82a-4b9d-b9c5-0f64b6755421&skt=2022-09-18T13%3A31%3A35Z&ske=2022-09-19T21%3A41%3A35Z&sks=b&skv=2019-07-07&st=2022-09-18T14%3A23%3A03Z&se=2022-09-18T22%3A33%3A03Z&sp=r'},\n",
              " 'submittedBy': 'Nazeer Ahmed'}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.train.hyperdrive import GridParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Create a Python environment for the experiment\n",
        "hyper_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/hyperdrive_env.yml\")\n",
        "\n",
        "# Get the training dataset\n",
        "# diabetes_ds = ws.datasets.get(\"sms spam dataset\")\n",
        "# dataset\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='train.py',\n",
        "                                # Add non-hyperparameter arguments -in this case, the training dataset\n",
        "                                arguments = ['--input-data', smsspam_ds.as_named_input('training_data')],\n",
        "                                environment=hyper_env,\n",
        "                                compute_target = aml_compute)\n",
        "\n",
        "# Sample a range of parameter values\n",
        "params = GridParameterSampling(\n",
        "    {\n",
        "        # Hyperdrive will try 6 combinations, adding these as script arguments\n",
        "        '--C': choice(0.01, 0.1, 1.0),\n",
        "        '--max_iter' : choice(10, 50)\n",
        "    }\n",
        ")\n",
        "\n",
        "# Configure hyperdrive settings\n",
        "hyperdrive = HyperDriveConfig(run_config=script_config, \n",
        "                          hyperparameter_sampling=params, \n",
        "                          policy=None, # No early stopping policy\n",
        "                          primary_metric_name='Accuracy', # Find the highest AUC metric\n",
        "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
        "                          max_total_runs=36, # Restict the experiment to 6 iterations\n",
        "                          max_concurrent_runs=2) # Run up to 2 iterations in parallel\n",
        "\n",
        "# Run the experiment\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=hyperdrive)\n",
        "\n",
        "# Show the status in the notebook as the experiment runs\n",
        "# RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Determine the best performing run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'run_id': 'HD_d62506a6-83b4-428d-9a1c-9f66759854a7_4', 'hyperparameters': '{\"--C\": 1.0, \"--max_iter\": 10}', 'best_primary_metric': 0.9503588516746412, 'status': 'Completed'}\n",
            "{'run_id': 'HD_d62506a6-83b4-428d-9a1c-9f66759854a7_5', 'hyperparameters': '{\"--C\": 1.0, \"--max_iter\": 50}', 'best_primary_metric': 0.9497607655502392, 'status': 'Completed'}\n",
            "{'run_id': 'HD_d62506a6-83b4-428d-9a1c-9f66759854a7_2', 'hyperparameters': '{\"--C\": 0.1, \"--max_iter\": 10}', 'best_primary_metric': 0.8726076555023924, 'status': 'Completed'}\n",
            "{'run_id': 'HD_d62506a6-83b4-428d-9a1c-9f66759854a7_3', 'hyperparameters': '{\"--C\": 0.1, \"--max_iter\": 50}', 'best_primary_metric': 0.8726076555023924, 'status': 'Completed'}\n",
            "{'run_id': 'HD_d62506a6-83b4-428d-9a1c-9f66759854a7_0', 'hyperparameters': '{\"--C\": 0.01, \"--max_iter\": 10}', 'best_primary_metric': 0.8606459330143541, 'status': 'Completed'}\n",
            "{'run_id': 'HD_d62506a6-83b4-428d-9a1c-9f66759854a7_1', 'hyperparameters': '{\"--C\": 0.01, \"--max_iter\": 50}', 'best_primary_metric': 0.8606459330143541, 'status': 'Completed'}\n"
          ]
        }
      ],
      "source": [
        "# Print all child runs, sorted by the primary metric\n",
        "for child_run in run.get_children_sorted_by_primary_metric():\n",
        "    print(child_run)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Run Id:  HD_d62506a6-83b4-428d-9a1c-9f66759854a7_4\n",
            " -AUC: 0.9522707411859093\n",
            " -Accuracy: 0.9503588516746412\n",
            " -Arguments: ['--input-data', 'DatasetConsumptionConfig:training_data', '--C', '1', '--max_iter', '10']\n"
          ]
        }
      ],
      "source": [
        "# Get the best run, and its metrics and arguments\n",
        "best_run = run.get_best_run_by_primary_metric()\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "script_arguments = best_run.get_details() ['runDefinition']['arguments']\n",
        "print('Best Run Id: ', best_run.id)\n",
        "print(' -AUC:', best_run_metrics['AUC'])\n",
        "print(' -Accuracy:', best_run_metrics['Accuracy'])\n",
        "print(' -Arguments:',script_arguments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>nb_lr_exp_0916_v6</td><td>HD_d62506a6-83b4-428d-9a1c-9f66759854a7_4</td><td>azureml.scriptrun</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/HD_d62506a6-83b4-428d-9a1c-9f66759854a7_4?wsid=/subscriptions/16bc73b5-82be-47f2-b5ab-f2373344794c/resourcegroups/epe-poc-nazeer/workspaces/nahmed30-azureml-workspace&amp;tid=db05faca-c82a-4b9d-b9c5-0f64b6755421\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ],
            "text/plain": [
              "Run(Experiment: nb_lr_exp_0916_v6,\n",
              "Id: HD_d62506a6-83b4-428d-9a1c-9f66759854a7_4,\n",
              "Type: azureml.scriptrun,\n",
              "Status: Completed)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_run.download_files()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that you've found the best run, you can register the model it trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model(workspace=Workspace.create(name='nahmed30-azureml-workspace', subscription_id='16bc73b5-82be-47f2-b5ab-f2373344794c', resource_group='epe-poc-nazeer'), name=sms-spam-hd-0917-v7-model, id=sms-spam-hd-0917-v7-model:1, version=1, tags={'Method': 'LogisticRegression Hyperdrive'}, properties={'Accuracy': '0.9503588516746412', 'AUC': '0.9522707411859093'})\n"
          ]
        }
      ],
      "source": [
        "# Register best model best model\n",
        "reg_model = best_run.register_model(model_name='sms-spam-hd-0917-v7-model',\n",
        "                                        model_path='outputs/model_v7.pkl', \n",
        "                                        tags={'Method':'LogisticRegression Hyperdrive'}, \n",
        "                                        properties={'Accuracy': best_run_metrics['Accuracy'],\n",
        "                                                    'AUC': best_run_metrics['AUC']})\n",
        "print(reg_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "azureml.core.model.Model"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(reg_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'sms-spam-hd-0917-v7-model:1'"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg_model.id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "gather": {
          "logged": 1663300879544
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'_azureml.ComputeTargetType': 'amlctrain',\n",
              " 'ContentSnapshotId': '596f8c31-04d6-46f0-ba36-973f47658aa9',\n",
              " 'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
              " 'ProcessStatusFile': 'azureml-logs/process_status.json'}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_run.get_properties()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1663300879791
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run(Experiment: nb_lr_exp_0916_v6,\n",
            "Id: HD_d62506a6-83b4-428d-9a1c-9f66759854a7_5,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n",
            "Run(Experiment: nb_lr_exp_0916_v6,\n",
            "Id: HD_d62506a6-83b4-428d-9a1c-9f66759854a7_4,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n",
            "Run(Experiment: nb_lr_exp_0916_v6,\n",
            "Id: HD_d62506a6-83b4-428d-9a1c-9f66759854a7_2,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n",
            "Run(Experiment: nb_lr_exp_0916_v6,\n",
            "Id: HD_d62506a6-83b4-428d-9a1c-9f66759854a7_3,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n",
            "Run(Experiment: nb_lr_exp_0916_v6,\n",
            "Id: HD_d62506a6-83b4-428d-9a1c-9f66759854a7_0,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n",
            "Run(Experiment: nb_lr_exp_0916_v6,\n",
            "Id: HD_d62506a6-83b4-428d-9a1c-9f66759854a7_1,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for child_run in run.get_children():\n",
        "    print(child_run,\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'sms-spam-hd-0917-v7-model'"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg_model.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "gather": {
          "logged": 1663300880215
        }
      },
      "outputs": [],
      "source": [
        "model_name = reg_model.name\n",
        "script_file = \"scripts/score_v1_1.py\"\n",
        "description = \"aml SMS spam lr hd project sdk\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "gather": {
          "logged": 1663300881569
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.automl.core.shared import constants\n",
        "env = best_run.get_environment()\n",
        "\n",
        "# best_run.download_file('outputs/scoring_file_v_1_0_0.py', script_file)\n",
        "# best_run.download_file(constants.CONDA_ENV_FILE_PATH, 'env.yml')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy the Best Model\n",
        "\n",
        "Run the following code to deploy the best model. You can see the state of the deployment in the Azure ML portal. This step can take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "inference_config = InferenceConfig(entry_script=script_file, environment=best_run.get_environment())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "InferenceConfig(entry_script=scripts/score_v1_1.py, runtime=None, conda_file=None, extra_docker_file_steps=None, source_directory=None, enable_gpu=None, base_image=None, base_image_registry=<azureml.core.container_registry.ContainerRegistry object at 0x7f8826b66b50>)"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inference_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
        "                                               memory_gb = 1,\n",
        "                                               tags = {'type': \"automl-SMS-spam-prediction\"},\n",
        "                                               description = 'Sample service for AutoML SMS Spam Prediction')\n",
        "\n",
        "aci_service_name = 'smsspam-lrhd-v7-12'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663301113175
        }
      },
      "outputs": [],
      "source": [
        "aci_service = Model.deploy(ws, aci_service_name, [reg_model], inference_config, aciconfig)\n",
        "aci_service.wait_for_deployment(True)\n",
        "print(aci_service.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ws"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_run.properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parameter_values = best_run.get_details() ['runDefinition']['arguments']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parameter_values "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelname=best_run.properties['model_name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(os.getenv('AZUREML_MODEL_DIR'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), './outputs/model_v6.pkl')\n",
        "\n",
        "print(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = 'sms-spam-hd-0916-v6-model'\n",
        "model_obj = Model(ws, model_name )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import azureml.core.model as Model\n",
        "model_path = Model.get_model_path('sms-spam-hd-0916-v6-model')\n",
        "print(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Consume the Endpoint\n",
        "You can add inputs to the following input sample. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663301113331
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "scoring_uri = aci_service.scoring_uri\n",
        "print(scoring_uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663301113485
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        " \n",
        "data = {\n",
        "  \"data\": [\n",
        "    {\n",
        "      \"v2\": \"Click link below to collect $10000\",\n",
        "      \"Column4\": \"example_value\",\n",
        "      \"Column5\": \"example_value\",\n",
        "      \"Column6\": \"example_value\"\n",
        "    }\n",
        "  ],\n",
        "  \"method\": \"predict\"\n",
        "}\n",
        "    \n",
        "# Convert to JSON string\n",
        "input_data = json.dumps(data)\n",
        "with open(\"data.json\", \"w\") as _f:\n",
        "    _f.write(input_data)\n",
        "\n",
        "# Set the content type\n",
        "headers = {'Content-Type': 'application/json'}\n",
        "# If authentication is enabled, set the authorization header\n",
        "#headers['Authorization'] = f'Bearer {key}'\n",
        "\n",
        "# Make the request and display the response\n",
        "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
        "print(\"prediction is :\" , resp.json())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663301562460
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        " \n",
        "data = {\n",
        "  \"data\": [\n",
        "    {\n",
        "      \"v2\": \"I'm waiting here see you soon\",\n",
        "      \"Column4\": \"example_value\",\n",
        "      \"Column5\": \"example_value\",\n",
        "      \"Column6\": \"example_value\"\n",
        "    }\n",
        "  ],\n",
        "  \"method\": \"predict\"\n",
        "}\n",
        "    \n",
        "# Convert to JSON string\n",
        "input_data = json.dumps(data)\n",
        "with open(\"data.json\", \"w\") as _f:\n",
        "    _f.write(input_data)\n",
        "\n",
        "# Set the content type\n",
        "headers = {'Content-Type': 'application/json'}\n",
        "# If authentication is enabled, set the authorization header\n",
        "#headers['Authorization'] = f'Bearer {key}'\n",
        "\n",
        "# Make the request and display the response\n",
        "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
        "print(\"prediction is :\" , resp.json())"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
